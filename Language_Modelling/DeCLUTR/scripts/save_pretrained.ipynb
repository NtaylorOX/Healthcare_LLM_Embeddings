{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/sdc/niallt/venvs/39_declutr/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import typer\n",
    "from allennlp.common import util as common_util\n",
    "from allennlp.models.archival import load_archive\n",
    "from allennlp.predictors import Predictor\n",
    "import argparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ConfigurationError",
     "evalue": "declutr not in acceptable choices for dataset_reader.type: ['babi', 'conll2003', 'interleaving', 'multitask', 'multitask_shim', 'sequence_tagging', 'sharded', 'text_classification_json']. You should either use the --include-package flag to make sure the correct module is loaded, or use a fully qualified class name in your config file like {\"model\": \"my_module.models.MyModel\"} to have it imported automatically.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mConfigurationError\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m overrides \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m{\u001b[39m\u001b[39m'\u001b[39m\u001b[39mtrainer.cuda_device\u001b[39m\u001b[39m'\u001b[39m\u001b[39m: -1}\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m      3\u001b[0m \u001b[39m# print(f\"archive file: {archive_file}\")\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m archive \u001b[39m=\u001b[39m load_archive(archive_file, overrides\u001b[39m=\u001b[39;49moverrides)\n",
      "File \u001b[0;32m~/DPhil_NLP/Language_Modelling/DeCLUTR/allennlp/allennlp/models/archival.py:232\u001b[0m, in \u001b[0;36mload_archive\u001b[0;34m(archive_file, cuda_device, overrides, weights_file)\u001b[0m\n\u001b[1;32m    229\u001b[0m config \u001b[39m=\u001b[39m Params\u001b[39m.\u001b[39mfrom_file(os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(serialization_dir, CONFIG_NAME), overrides)\n\u001b[1;32m    231\u001b[0m \u001b[39m# Instantiate model and dataset readers. Use a duplicate of the config, as it will get consumed.\u001b[39;00m\n\u001b[0;32m--> 232\u001b[0m dataset_reader, validation_dataset_reader \u001b[39m=\u001b[39m _load_dataset_readers(\n\u001b[1;32m    233\u001b[0m     config\u001b[39m.\u001b[39;49mduplicate(), serialization_dir\n\u001b[1;32m    234\u001b[0m )\n\u001b[1;32m    235\u001b[0m model \u001b[39m=\u001b[39m _load_model(config\u001b[39m.\u001b[39mduplicate(), weights_path, serialization_dir, cuda_device)\n\u001b[1;32m    237\u001b[0m \u001b[39m# Load meta.\u001b[39;00m\n",
      "File \u001b[0;32m~/DPhil_NLP/Language_Modelling/DeCLUTR/allennlp/allennlp/models/archival.py:268\u001b[0m, in \u001b[0;36m_load_dataset_readers\u001b[0;34m(config, serialization_dir)\u001b[0m\n\u001b[1;32m    262\u001b[0m \u001b[39m# Try to use the validation dataset reader if there is one - otherwise fall back\u001b[39;00m\n\u001b[1;32m    263\u001b[0m \u001b[39m# to the default dataset_reader used for both training and validation.\u001b[39;00m\n\u001b[1;32m    264\u001b[0m validation_dataset_reader_params \u001b[39m=\u001b[39m config\u001b[39m.\u001b[39mget(\n\u001b[1;32m    265\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mvalidation_dataset_reader\u001b[39m\u001b[39m\"\u001b[39m, dataset_reader_params\u001b[39m.\u001b[39mduplicate()\n\u001b[1;32m    266\u001b[0m )\n\u001b[0;32m--> 268\u001b[0m dataset_reader \u001b[39m=\u001b[39m DatasetReader\u001b[39m.\u001b[39;49mfrom_params(\n\u001b[1;32m    269\u001b[0m     dataset_reader_params, serialization_dir\u001b[39m=\u001b[39;49mserialization_dir\n\u001b[1;32m    270\u001b[0m )\n\u001b[1;32m    271\u001b[0m validation_dataset_reader \u001b[39m=\u001b[39m DatasetReader\u001b[39m.\u001b[39mfrom_params(\n\u001b[1;32m    272\u001b[0m     validation_dataset_reader_params, serialization_dir\u001b[39m=\u001b[39mserialization_dir\n\u001b[1;32m    273\u001b[0m )\n\u001b[1;32m    275\u001b[0m \u001b[39mreturn\u001b[39;00m dataset_reader, validation_dataset_reader\n",
      "File \u001b[0;32m~/DPhil_NLP/Language_Modelling/DeCLUTR/allennlp/allennlp/common/from_params.py:585\u001b[0m, in \u001b[0;36mFromParams.from_params\u001b[0;34m(cls, params, constructor_to_call, constructor_to_inspect, **extras)\u001b[0m\n\u001b[1;32m    583\u001b[0m as_registrable \u001b[39m=\u001b[39m cast(Type[Registrable], \u001b[39mcls\u001b[39m)\n\u001b[1;32m    584\u001b[0m default_to_first_choice \u001b[39m=\u001b[39m as_registrable\u001b[39m.\u001b[39mdefault_implementation \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m--> 585\u001b[0m choice \u001b[39m=\u001b[39m params\u001b[39m.\u001b[39;49mpop_choice(\n\u001b[1;32m    586\u001b[0m     \u001b[39m\"\u001b[39;49m\u001b[39mtype\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    587\u001b[0m     choices\u001b[39m=\u001b[39;49mas_registrable\u001b[39m.\u001b[39;49mlist_available(),\n\u001b[1;32m    588\u001b[0m     default_to_first_choice\u001b[39m=\u001b[39;49mdefault_to_first_choice,\n\u001b[1;32m    589\u001b[0m )\n\u001b[1;32m    590\u001b[0m subclass, constructor_name \u001b[39m=\u001b[39m as_registrable\u001b[39m.\u001b[39mresolve_class_name(choice)\n\u001b[1;32m    591\u001b[0m \u001b[39m# See the docstring for an explanation of what's going on here.\u001b[39;00m\n",
      "File \u001b[0;32m~/DPhil_NLP/Language_Modelling/DeCLUTR/allennlp/allennlp/common/params.py:324\u001b[0m, in \u001b[0;36mParams.pop_choice\u001b[0;34m(self, key, choices, default_to_first_choice, allow_class_names)\u001b[0m\n\u001b[1;32m    317\u001b[0m     key_str \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhistory \u001b[39m+\u001b[39m key\n\u001b[1;32m    318\u001b[0m     message \u001b[39m=\u001b[39m (\n\u001b[1;32m    319\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mvalue\u001b[39m}\u001b[39;00m\u001b[39m not in acceptable choices for \u001b[39m\u001b[39m{\u001b[39;00mkey_str\u001b[39m}\u001b[39;00m\u001b[39m: \u001b[39m\u001b[39m{\u001b[39;00mchoices\u001b[39m}\u001b[39;00m\u001b[39m. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    320\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mYou should either use the --include-package flag to make sure the correct module \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    321\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mis loaded, or use a fully qualified class name in your config file like \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    322\u001b[0m \u001b[39m        \u001b[39m\u001b[39m\"\"\"{\"model\": \"my_module.models.MyModel\"} to have it imported automatically.\"\"\"\u001b[39;00m\n\u001b[1;32m    323\u001b[0m     )\n\u001b[0;32m--> 324\u001b[0m     \u001b[39mraise\u001b[39;00m ConfigurationError(message)\n\u001b[1;32m    325\u001b[0m \u001b[39mreturn\u001b[39;00m value\n",
      "\u001b[0;31mConfigurationError\u001b[0m: declutr not in acceptable choices for dataset_reader.type: ['babi', 'conll2003', 'interleaving', 'multitask', 'multitask_shim', 'sequence_tagging', 'sharded', 'text_classification_json']. You should either use the --include-package flag to make sure the correct module is loaded, or use a fully qualified class name in your config file like {\"model\": \"my_module.models.MyModel\"} to have it imported automatically."
     ]
    }
   ],
   "source": [
    "archive_file = \"/mnt/sdc/niallt/saved_models/declutr/mimic/few_epoch/mimic-roberta-base/code_testing/\"\n",
    "overrides = \"{'trainer.cuda_device': -1}\"\n",
    "# print(f\"archive file: {archive_file}\")\n",
    "\n",
    "archive = load_archive(archive_file, overrides=overrides)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "39_declutr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
