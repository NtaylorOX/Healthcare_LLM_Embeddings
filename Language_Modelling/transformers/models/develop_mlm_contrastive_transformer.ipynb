{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"9\" #6,7\n",
    "from transformers import (\n",
    "    PreTrainedModel,\n",
    "    RobertaPreTrainedModel, \n",
    "    RobertaModel, \n",
    "    PretrainedConfig, \n",
    "    RobertaConfig, \n",
    "    RobertaForSequenceClassification,\n",
    "    AutoModelForSequenceClassification,AutoModelForCausalLM,AutoModelForMaskedLM, \n",
    "    AutoConfig, \n",
    "    AutoModel,\n",
    "    AutoTokenizer,\n",
    "    RobertaPreTrainedModel,\n",
    "    BertForPreTraining,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    DataCollatorForLanguageModeling\n",
    ")\n",
    "\n",
    "from transformers.modeling_outputs import (\n",
    "    BaseModelOutputWithPastAndCrossAttentions,\n",
    "    BaseModelOutputWithPoolingAndCrossAttentions,\n",
    "    CausalLMOutputWithCrossAttentions,\n",
    "    MaskedLMOutput,\n",
    "    MultipleChoiceModelOutput,\n",
    "    NextSentencePredictorOutput,\n",
    "    QuestionAnsweringModelOutput,\n",
    "    SequenceClassifierOutput,\n",
    "    TokenClassifierOutput,\n",
    ")\n",
    "\n",
    "from transformers.trainer_utils import (\n",
    "    PREFIX_CHECKPOINT_DIR,\n",
    "    BestRun,\n",
    "    EvalLoopOutput,\n",
    "    EvalPrediction,\n",
    "    FSDPOption,\n",
    "    HPSearchBackend,\n",
    "    HubStrategy,\n",
    "    IntervalStrategy,\n",
    "    PredictionOutput,\n",
    "    RemoveColumnsCollator,\n",
    "    ShardedDDPOption,\n",
    "    TrainerMemoryTracker,\n",
    "    TrainOutput,\n",
    "    default_compute_objective,\n",
    "    default_hp_space,\n",
    "    denumpify_detensorize,\n",
    "    enable_full_determinism,\n",
    "    find_executable_batch_size,\n",
    "    get_last_checkpoint,\n",
    "    has_length,\n",
    "    number_of_arguments,\n",
    "    seed_worker,\n",
    "    set_seed,\n",
    "    speed_metrics,\n",
    ")\n",
    "\n",
    "from transformers.utils import logging\n",
    "\n",
    "from transformers.configuration_utils import PretrainedConfig\n",
    "from transformers.data.data_collator import DataCollator, DataCollatorWithPadding, default_data_collator\n",
    "from transformers.debug_utils import DebugOption, DebugUnderflowOverflow\n",
    "from transformers.deepspeed import deepspeed_init, is_deepspeed_zero3_enabled\n",
    "from transformers.dependency_versions_check import dep_version_check\n",
    "from transformers.modelcard import TrainingSummary\n",
    "from transformers.modeling_utils import PreTrainedModel, load_sharded_checkpoint, unwrap_model\n",
    "from transformers.models.auto.modeling_auto import MODEL_FOR_CAUSAL_LM_MAPPING_NAMES, MODEL_MAPPING_NAMES\n",
    "from transformers.optimization import Adafactor, get_scheduler\n",
    "# from transformers.pytorch_utils import ALL_LAYERNORM_LAYERS, is_torch_greater_or_equal_than_1_10, is_torch_less_than_1_11\n",
    "from transformers.tokenization_utils_base import PreTrainedTokenizerBase\n",
    "from transformers.trainer_callback import (\n",
    "    CallbackHandler,\n",
    "    DefaultFlowCallback,\n",
    "    PrinterCallback,\n",
    "    ProgressCallback,\n",
    "    TrainerCallback,\n",
    "    TrainerControl,\n",
    "    TrainerState,\n",
    ")\n",
    "from transformers.trainer_pt_utils import (\n",
    "    DistributedLengthGroupedSampler,\n",
    "    DistributedSamplerWithLoop,\n",
    "    DistributedTensorGatherer,\n",
    "    IterableDatasetShard,\n",
    "    LabelSmoother,\n",
    "    LengthGroupedSampler,\n",
    "    SequentialDistributedSampler,\n",
    "    ShardSampler,\n",
    "    distributed_broadcast_scalars,\n",
    "    distributed_concat,\n",
    "    find_batch_size,\n",
    "    get_module_class_from_name,\n",
    "    get_parameter_names,\n",
    "    nested_concat,\n",
    "    nested_detach,\n",
    "    nested_numpify,\n",
    "    nested_truncate,\n",
    "    nested_xla_mesh_reduce,\n",
    "    reissue_pt_warnings,\n",
    ")\n",
    "import time\n",
    "\n",
    "from torch.utils.data import DataLoader, Dataset, RandomSampler, SequentialSampler\n",
    "from torch.utils.data.distributed import DistributedSampler\n",
    "\n",
    "\n",
    "# from transformers.utils.generic import can_return_loss\n",
    "# custom\n",
    "from mlm_contrastive_transformer import TransformerForPreTraining\n",
    "\n",
    "import math\n",
    "from typing import List, Optional, Tuple, Union\n",
    "\n",
    "import torch\n",
    "import torch.utils.checkpoint\n",
    "from torch import nn\n",
    "from torch.nn import BCEWithLogitsLoss, CrossEntropyLoss, MSELoss\n",
    "\n",
    "from datasets import load_dataset, load_metric # list_datasets, load_from_disk, DatasetDict, Dataset, load_dataset_builder\n",
    "import evaluate # this weirdly loads something onto the GPU and will cause OOM on python3.9\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import copy\n",
    "from typing import TYPE_CHECKING, Any, Callable, Dict, List, Optional, Tuple, Union\n",
    "from sentence_transformers.losses import CosineSimilarityLoss\n",
    "\n",
    "\n",
    "from utils.custom_hf_trainer import CustomHFTrainer\n",
    "\n",
    "\n",
    "from peft import get_peft_config, get_peft_model, LoraConfig, TaskType\n",
    "from peft import (\n",
    "    get_peft_config,\n",
    "    get_peft_model,\n",
    "    get_peft_model_state_dict,\n",
    "    set_peft_model_state_dict,\n",
    "    PeftType,\n",
    "    PeftConfig,\n",
    "    PeftModel,\n",
    "    PrefixTuningConfig,\n",
    "    PromptEncoderConfig,\n",
    "    PromptTuningConfig,\n",
    "    prepare_model_for_int8_training,\n",
    "    # AutoPeftModel,\n",
    "    prepare_model_for_kbit_training # only for latest dev version of peft\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers.trainer_utils import EvalPrediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = EvalPrediction([1],[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.predictions"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### first lets look at getting dataset in a suitable format\n",
    "\n",
    "we simply need to create a dataset that can be used for both MLM and contrastive loss calculation. This actually may work well with HF new setfit library: https://github.com/huggingface/setfit, although we want to extend this to include MLM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_dir = \"/mnt/sdg/niallt/mimic_iii/processed/HADM_ID_split/pseudo_classification/class_reduced_8/fewshot_16/\"\n",
    "data_dir = \"/mnt/sdc/niallt/mimic_iii/processed/HADM_ID_split/\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset csv (/mnt/sdc/niallt/.cache/csv/default-e82d422e95c8b033/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d3442c9246a4e4ba66333a3b5ffb6f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# load as a dataset\n",
    "dataset = load_dataset(\"csv\", \n",
    "                        data_files = {\"train\":f\"{data_dir}/lm_pretraining_train_250000.csv\",\n",
    "                                        \"valid\":f\"{data_dir}/lm_pretraining_test_1000.csv\"},\n",
    "                        cache_dir = \"/mnt/sdc/niallt/.cache/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['TEXT', 'CATEGORY', 'label'],\n",
       "    num_rows: 1000\n",
       "})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['valid']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'TEXT': '9:27 pm ct low ext w/o c left; ct low ext w/o c right clip # ct reconstruction reason: please evaluate bilateral lower leg, ankles, feet for trauma admitting diagnosis: s/p fall medical condition: 37 year old man s/p fall from 70 feet reason for this examination: please evaluate bilateral lower leg, ankles, feet for trauma no contraindications for iv contrast final report indication: status post fall from 70 feet with bilateral foot fractures. technique: helically acquired contiguous axial images were obtained from the distal tibia and fibula through the proximal forefoot in both the right and left feet. coronal and sagittal reformatted images were performed for both feet. ct right foot with sagittal and coronal reformats: there is a markedly comminuted fracture involving the entire body of the calcaneus. in addition, the ankle mortise is completely disrupted with fracture through the neck of the talus and inferior medial displacement of the talar body. the talar body is also anteriorly angulated. the disruption of the ankle mortise is also complicated by numerous bone fragments within joint space. the anterior talus communicates normally with the navicular bone. in addition, the anterior most fragment of the calcaneus articulates with the cuboid. there is a pin extending through the distal tibia into the posterior aspect of the talar dome and through multiple calcaneal fragments. ct left foot with coronal and sagittal reformatted images: there is marked comminuted fracture involving the entire calcaneus. the talocalcaneal joint is disrupted. however, the ankle mortise is preserved. there is disruption of the talonavicular joint with anterior superior slight displacement of the navicular bone and slight widening of the dorsal aspect of this articulation. there is a linear fracture also along the long axis of the first metatarsal bone, extending into the tarsometatarsal joint. there is a minimally displaced fracture through the dorsal aspect of the lateral cuneiform. lastly, there is a nondisplaced fracture through the distal fibula. impression: complex fractures of both feet, with complete disruption of the right ankle mortise.',\n",
       " 'CATEGORY': 'Radiology',\n",
       " 'label': 1}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[\"train\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['TEXT', 'CATEGORY', 'label'],\n",
       "    num_rows: 249994\n",
       "})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.rename_column('label', 'category_label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'TEXT': '9:27 pm ct low ext w/o c left; ct low ext w/o c right clip # ct reconstruction reason: please evaluate bilateral lower leg, ankles, feet for trauma admitting diagnosis: s/p fall medical condition: 37 year old man s/p fall from 70 feet reason for this examination: please evaluate bilateral lower leg, ankles, feet for trauma no contraindications for iv contrast final report indication: status post fall from 70 feet with bilateral foot fractures. technique: helically acquired contiguous axial images were obtained from the distal tibia and fibula through the proximal forefoot in both the right and left feet. coronal and sagittal reformatted images were performed for both feet. ct right foot with sagittal and coronal reformats: there is a markedly comminuted fracture involving the entire body of the calcaneus. in addition, the ankle mortise is completely disrupted with fracture through the neck of the talus and inferior medial displacement of the talar body. the talar body is also anteriorly angulated. the disruption of the ankle mortise is also complicated by numerous bone fragments within joint space. the anterior talus communicates normally with the navicular bone. in addition, the anterior most fragment of the calcaneus articulates with the cuboid. there is a pin extending through the distal tibia into the posterior aspect of the talar dome and through multiple calcaneal fragments. ct left foot with coronal and sagittal reformatted images: there is marked comminuted fracture involving the entire calcaneus. the talocalcaneal joint is disrupted. however, the ankle mortise is preserved. there is disruption of the talonavicular joint with anterior superior slight displacement of the navicular bone and slight widening of the dorsal aspect of this articulation. there is a linear fracture also along the long axis of the first metatarsal bone, extending into the tarsometatarsal joint. there is a minimally displaced fracture through the dorsal aspect of the lateral cuneiform. lastly, there is a nondisplaced fracture through the distal fibula. impression: complex fractures of both feet, with complete disruption of the right ankle mortise.',\n",
       " 'CATEGORY': 'Radiology',\n",
       " 'category_label': 1}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[\"train\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Could not locate the tokenizer configuration file, will try to use the model config instead.\n",
      "loading configuration file config.json from cache at /home/niallt/.cache/huggingface/hub/models--roberta-base/snapshots/bc2764f8af2e92b6eb5679868df33e224075ca68/config.json\n",
      "Model config RobertaConfig {\n",
      "  \"_name_or_path\": \"roberta-base\",\n",
      "  \"architectures\": [\n",
      "    \"RobertaForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.30.2\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "loading file vocab.json from cache at /home/niallt/.cache/huggingface/hub/models--roberta-base/snapshots/bc2764f8af2e92b6eb5679868df33e224075ca68/vocab.json\n",
      "loading file merges.txt from cache at /home/niallt/.cache/huggingface/hub/models--roberta-base/snapshots/bc2764f8af2e92b6eb5679868df33e224075ca68/merges.txt\n",
      "loading file tokenizer.json from cache at /home/niallt/.cache/huggingface/hub/models--roberta-base/snapshots/bc2764f8af2e92b6eb5679868df33e224075ca68/tokenizer.json\n",
      "loading file added_tokens.json from cache at None\n",
      "loading file special_tokens_map.json from cache at None\n",
      "loading file tokenizer_config.json from cache at None\n",
      "loading configuration file config.json from cache at /home/niallt/.cache/huggingface/hub/models--roberta-base/snapshots/bc2764f8af2e92b6eb5679868df33e224075ca68/config.json\n",
      "Model config RobertaConfig {\n",
      "  \"_name_or_path\": \"roberta-base\",\n",
      "  \"architectures\": [\n",
      "    \"RobertaForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.30.2\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "loading configuration file config.json from cache at /home/niallt/.cache/huggingface/hub/models--roberta-base/snapshots/bc2764f8af2e92b6eb5679868df33e224075ca68/config.json\n",
      "Model config MeanRobertaConfig {\n",
      "  \"architectures\": [\n",
      "    \"RobertaForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"compute_contrastive\": true,\n",
      "  \"contrastive_loss_weight\": 1.0,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_pretraining_labels\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.30.2\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "loading weights file model.safetensors from cache at /home/niallt/.cache/huggingface/hub/models--roberta-base/snapshots/bc2764f8af2e92b6eb5679868df33e224075ca68/model.safetensors\n",
      "All model checkpoint weights were used when initializing TransformerForPreTraining.\n",
      "\n",
      "Some weights of TransformerForPreTraining were not initialized from the model checkpoint at roberta-base and are newly initialized: ['seq_classifier.classifier.bias', 'seq_classifier.classifier.weight', 'lm_head.decoder.bias', 'lm_head.decoder.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "loading configuration file config.json from cache at /home/niallt/.cache/huggingface/hub/models--roberta-base/snapshots/bc2764f8af2e92b6eb5679868df33e224075ca68/config.json\n",
      "Model config RobertaConfig {\n",
      "  \"architectures\": [\n",
      "    \"RobertaForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.30.2\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "loading weights file model.safetensors from cache at /home/niallt/.cache/huggingface/hub/models--roberta-base/snapshots/bc2764f8af2e92b6eb5679868df33e224075ca68/model.safetensors\n",
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.bias']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# first we can try just modelling the task similar to that of the next sentence prediction task\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained('roberta-base')\n",
    "# model = BertForPreTraining.from_pretrained('bert-base-uncased')\n",
    "model = TransformerForPreTraining.from_pretrained('roberta-base', compute_contrastive = True)\n",
    "normal_model = RobertaModel.from_pretrained('roberta-base')\n",
    "# model = AutoModelForMaskedLM.from_pretrained('roberta-base')\n",
    "\n",
    "sentence_A = \"The sun is a huge ball of gases. It has a diameter of 1,392,000 km.\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for counting trainable params\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "# function to unfreeze all layers of a model\n",
    "\n",
    "def unfreeze_model(model):\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "124645632"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_parameters(normal_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "124706661"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_parameters(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9228"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_parameters(model.seq_classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MeanRobertaConfig {\n",
       "  \"_name_or_path\": \"roberta-base\",\n",
       "  \"architectures\": [\n",
       "    \"RobertaForMaskedLM\"\n",
       "  ],\n",
       "  \"attention_probs_dropout_prob\": 0.1,\n",
       "  \"bos_token_id\": 0,\n",
       "  \"classifier_dropout\": null,\n",
       "  \"compute_contrastive\": true,\n",
       "  \"eos_token_id\": 2,\n",
       "  \"hidden_act\": \"gelu\",\n",
       "  \"hidden_dropout_prob\": 0.1,\n",
       "  \"hidden_size\": 768,\n",
       "  \"initializer_range\": 0.02,\n",
       "  \"intermediate_size\": 3072,\n",
       "  \"layer_norm_eps\": 1e-05,\n",
       "  \"max_position_embeddings\": 514,\n",
       "  \"model_type\": \"roberta\",\n",
       "  \"num_attention_heads\": 12,\n",
       "  \"num_hidden_layers\": 12,\n",
       "  \"pad_token_id\": 1,\n",
       "  \"position_embedding_type\": \"absolute\",\n",
       "  \"transformers_version\": \"4.26.1\",\n",
       "  \"type_vocab_size\": 1,\n",
       "  \"use_cache\": true,\n",
       "  \"vocab_size\": 50265\n",
       "}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compute_contrastive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### sanity check the re-loading of pre-trained model with autoclasses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file /mnt/sdc/niallt/saved_models/language_modelling/mimic/roberta-base-mimic-note-custom_pretraining_max_epoch_2_weighted/sampled_250000/07-07-2023--08-30/checkpoint-30000/config.json\n",
      "Model config MeanRobertaConfig {\n",
      "  \"_name_or_path\": \"roberta-base\",\n",
      "  \"architectures\": [\n",
      "    \"TransformerForPreTraining\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"compute_contrastive\": false,\n",
      "  \"contrastive_loss_weight\": 0.1,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_pretraining_labels\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.30.2\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "loading weights file /mnt/sdc/niallt/saved_models/language_modelling/mimic/roberta-base-mimic-note-custom_pretraining_max_epoch_2_weighted/sampled_250000/07-07-2023--08-30/checkpoint-30000/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing TransformerForPreTraining.\n",
      "\n",
      "All the weights of TransformerForPreTraining were initialized from the model checkpoint at /mnt/sdc/niallt/saved_models/language_modelling/mimic/roberta-base-mimic-note-custom_pretraining_max_epoch_2_weighted/sampled_250000/07-07-2023--08-30/checkpoint-30000/.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TransformerForPreTraining for predictions without further training.\n",
      "loading configuration file /mnt/sdc/niallt/saved_models/language_modelling/mimic/roberta-base-mimic-note-custom_pretraining_max_epoch_2_weighted/sampled_250000/07-07-2023--08-30/checkpoint-30000/config.json\n",
      "Model config RobertaConfig {\n",
      "  \"_name_or_path\": \"/mnt/sdc/niallt/saved_models/language_modelling/mimic/roberta-base-mimic-note-custom_pretraining_max_epoch_2_weighted/sampled_250000/07-07-2023--08-30/checkpoint-30000/\",\n",
      "  \"architectures\": [\n",
      "    \"TransformerForPreTraining\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"compute_contrastive\": false,\n",
      "  \"contrastive_loss_weight\": 0.1,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_pretraining_labels\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.30.2\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "loading weights file /mnt/sdc/niallt/saved_models/language_modelling/mimic/roberta-base-mimic-note-custom_pretraining_max_epoch_2_weighted/sampled_250000/07-07-2023--08-30/checkpoint-30000/pytorch_model.bin\n",
      "Some weights of the model checkpoint at /mnt/sdc/niallt/saved_models/language_modelling/mimic/roberta-base-mimic-note-custom_pretraining_max_epoch_2_weighted/sampled_250000/07-07-2023--08-30/checkpoint-30000/ were not used when initializing RobertaModel: ['lm_head.layer_norm.weight', 'lm_head.dense.bias', 'lm_head.decoder.weight', 'lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.decoder.bias', 'seq_classifier.classifier.bias', 'lm_head.dense.weight', 'seq_classifier.classifier.weight']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at /mnt/sdc/niallt/saved_models/language_modelling/mimic/roberta-base-mimic-note-custom_pretraining_max_epoch_2_weighted/sampled_250000/07-07-2023--08-30/checkpoint-30000/ and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "loading configuration file /mnt/sdc/niallt/saved_models/language_modelling/mimic/roberta-base-mimic-note-custom_pretraining_max_epoch_2_weighted/sampled_250000/07-07-2023--08-30/checkpoint-30000/config.json\n",
      "Model config RobertaConfig {\n",
      "  \"_name_or_path\": \"/mnt/sdc/niallt/saved_models/language_modelling/mimic/roberta-base-mimic-note-custom_pretraining_max_epoch_2_weighted/sampled_250000/07-07-2023--08-30/checkpoint-30000/\",\n",
      "  \"architectures\": [\n",
      "    \"TransformerForPreTraining\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"compute_contrastive\": false,\n",
      "  \"contrastive_loss_weight\": 0.1,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_pretraining_labels\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.30.2\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "loading weights file /mnt/sdc/niallt/saved_models/language_modelling/mimic/roberta-base-mimic-note-custom_pretraining_max_epoch_2_weighted/sampled_250000/07-07-2023--08-30/checkpoint-30000/pytorch_model.bin\n",
      "Some weights of the model checkpoint at /mnt/sdc/niallt/saved_models/language_modelling/mimic/roberta-base-mimic-note-custom_pretraining_max_epoch_2_weighted/sampled_250000/07-07-2023--08-30/checkpoint-30000/ were not used when initializing RobertaForSequenceClassification: ['lm_head.layer_norm.weight', 'lm_head.dense.bias', 'lm_head.decoder.weight', 'lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.decoder.bias', 'seq_classifier.classifier.bias', 'lm_head.dense.weight', 'seq_classifier.classifier.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at /mnt/sdc/niallt/saved_models/language_modelling/mimic/roberta-base-mimic-note-custom_pretraining_max_epoch_2_weighted/sampled_250000/07-07-2023--08-30/checkpoint-30000/ and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model_name_or_path = \"/mnt/sdc/niallt/saved_models/language_modelling/mimic/roberta-base-mimic-note-custom_pretraining_max_epoch_2_weighted/sampled_250000/07-07-2023--08-30/checkpoint-30000/\"\n",
    "model = TransformerForPreTraining.from_pretrained(model_name_or_path)\n",
    "normal_model = AutoModel.from_pretrained(model_name_or_path)\n",
    "auto_seq_model = AutoModelForSequenceClassification.from_pretrained(model_name_or_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TransformerForPreTraining(\n",
       "  (roberta): RobertaModel(\n",
       "    (embeddings): RobertaEmbeddings(\n",
       "      (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
       "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "      (token_type_embeddings): Embedding(1, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): RobertaEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (lm_head): RobertaLMHead(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "    (decoder): Linear(in_features=768, out_features=50265, bias=True)\n",
       "  )\n",
       "  (seq_classifier): MeanSequenceClassifier(\n",
       "    (classifier): Linear(in_features=768, out_features=12, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RobertaModel(\n",
       "  (embeddings): RobertaEmbeddings(\n",
       "    (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
       "    (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "    (token_type_embeddings): Embedding(1, 768)\n",
       "    (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (encoder): RobertaEncoder(\n",
       "    (layer): ModuleList(\n",
       "      (0-11): 12 x RobertaLayer(\n",
       "        (attention): RobertaAttention(\n",
       "          (self): RobertaSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): RobertaSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): RobertaIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): RobertaOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pooler): RobertaPooler(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (activation): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normal_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-0.0105,  0.0309, -0.0421,  ..., -0.0065, -0.0530,  0.0125],\n",
       "        [ 0.0153,  0.0162, -0.0054,  ...,  0.0245,  0.0304, -0.0195],\n",
       "        [ 0.0048,  0.0226,  0.0373,  ..., -0.0535, -0.0157, -0.0376],\n",
       "        ...,\n",
       "        [ 0.0049, -0.0030, -0.0031,  ...,  0.0020, -0.0003,  0.0297],\n",
       "        [-0.0070, -0.0124,  0.0054,  ..., -0.0137, -0.0105,  0.0135],\n",
       "        [ 0.0169,  0.0085,  0.0334,  ...,  0.0027,  0.0008,  0.0009]],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.roberta.encoder.layer[0].attention.self.value.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-0.0105,  0.0309, -0.0421,  ..., -0.0065, -0.0530,  0.0125],\n",
       "        [ 0.0153,  0.0162, -0.0054,  ...,  0.0245,  0.0304, -0.0195],\n",
       "        [ 0.0048,  0.0226,  0.0373,  ..., -0.0535, -0.0157, -0.0376],\n",
       "        ...,\n",
       "        [ 0.0049, -0.0030, -0.0031,  ...,  0.0020, -0.0003,  0.0297],\n",
       "        [-0.0070, -0.0124,  0.0054,  ..., -0.0137, -0.0105,  0.0135],\n",
       "        [ 0.0169,  0.0085,  0.0334,  ...,  0.0027,  0.0008,  0.0009]],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normal_model.encoder.layer[0].attention.self.value.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-0.0105,  0.0309, -0.0421,  ..., -0.0065, -0.0530,  0.0125],\n",
       "        [ 0.0153,  0.0162, -0.0054,  ...,  0.0245,  0.0304, -0.0195],\n",
       "        [ 0.0048,  0.0226,  0.0373,  ..., -0.0535, -0.0157, -0.0376],\n",
       "        ...,\n",
       "        [ 0.0049, -0.0030, -0.0031,  ...,  0.0020, -0.0003,  0.0297],\n",
       "        [-0.0070, -0.0124,  0.0054,  ..., -0.0137, -0.0105,  0.0135],\n",
       "        [ 0.0169,  0.0085,  0.0334,  ...,  0.0027,  0.0008,  0.0009]],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auto_seq_model.roberta.encoder.layer[0].attention.self.value.weight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Peft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 0.0856,  0.0398, -0.1010,  ..., -0.1160, -0.0837, -0.1936],\n",
       "        [ 0.0541, -0.2281,  0.1569,  ..., -0.1597,  0.0917, -0.0688],\n",
       "        [-0.0638,  0.0168, -0.0046,  ..., -0.0151,  0.0552, -0.1130],\n",
       "        ...,\n",
       "        [ 0.1296, -0.0342,  0.0183,  ..., -0.0726, -0.0778, -0.0231],\n",
       "        [ 0.1559,  0.1121, -0.0817,  ..., -0.0249,  0.0630, -0.2340],\n",
       "        [ 0.0315,  0.0698, -0.0776,  ...,  0.1595,  0.0075,  0.0934]],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normal_model.encoder.layer[0].attention.self.key.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "peft_type = PeftType.LORA\n",
    "lr = 3e-4\n",
    "peft_config = LoraConfig(task_type=None, inference_mode=False, r=8, lora_alpha=16, lora_dropout=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loroberta  = get_peft_model(normal_model, peft_config)\n",
    "peft_roberta = get_peft_model(model, peft_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 0.0856,  0.0398, -0.1010,  ..., -0.1160, -0.0837, -0.1936],\n",
       "        [ 0.0541, -0.2281,  0.1569,  ..., -0.1597,  0.0917, -0.0688],\n",
       "        [-0.0638,  0.0168, -0.0046,  ..., -0.0151,  0.0552, -0.1130],\n",
       "        ...,\n",
       "        [ 0.1296, -0.0342,  0.0183,  ..., -0.0726, -0.0778, -0.0231],\n",
       "        [ 0.1559,  0.1121, -0.0817,  ..., -0.0249,  0.0630, -0.2340],\n",
       "        [ 0.0315,  0.0698, -0.0776,  ...,  0.1595,  0.0075,  0.0934]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.base_model.model.roberta.encoder.layer[0].attention.self.key.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 294,912 || all params: 125,001,573 || trainable%: 0.23592663109927425\n"
     ]
    }
   ],
   "source": [
    "peft_roberta.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "294912"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_parameters(peft_roberta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MeanSequenceClassifier(\n",
       "  (classifier): Linear(in_features=768, out_features=12, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "peft_roberta.base_model.seq_classifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# need to unfreeze the classifier\n",
    "\n",
    "unfreeze_model(peft_roberta.base_model.seq_classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "304140"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_parameters(peft_roberta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 304,140 || all params: 125,001,573 || trainable%: 0.24330893820032168\n"
     ]
    }
   ],
   "source": [
    "peft_roberta.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RobertaConfig {\n",
       "  \"_name_or_path\": \"roberta-base\",\n",
       "  \"architectures\": [\n",
       "    \"RobertaForMaskedLM\"\n",
       "  ],\n",
       "  \"attention_probs_dropout_prob\": 0.1,\n",
       "  \"bos_token_id\": 0,\n",
       "  \"classifier_dropout\": null,\n",
       "  \"eos_token_id\": 2,\n",
       "  \"hidden_act\": \"gelu\",\n",
       "  \"hidden_dropout_prob\": 0.1,\n",
       "  \"hidden_size\": 768,\n",
       "  \"initializer_range\": 0.02,\n",
       "  \"intermediate_size\": 3072,\n",
       "  \"layer_norm_eps\": 1e-05,\n",
       "  \"max_position_embeddings\": 514,\n",
       "  \"model_type\": \"roberta\",\n",
       "  \"num_attention_heads\": 12,\n",
       "  \"num_hidden_layers\": 12,\n",
       "  \"pad_token_id\": 1,\n",
       "  \"position_embedding_type\": \"absolute\",\n",
       "  \"transformers_version\": \"4.30.2\",\n",
       "  \"type_vocab_size\": 1,\n",
       "  \"use_cache\": true,\n",
       "  \"vocab_size\": 50265\n",
       "}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normal_model.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['input_ids', 'attention_mask'])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized = tokenizer(sentence_A, return_tensors='pt')\n",
    "tokenized.keys()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[    0,   133,  3778,    16,    10,  1307,  1011,     9, 20038,     4,\n",
       "            85,    34,    10, 26089,     9,   112,     6, 36350,     6,   151,\n",
       "          6301,     4,     2]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = torch.LongTensor([0])\n",
    "labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PeftModel(\n",
       "  (base_model): LoraModel(\n",
       "    (model): TransformerForPreTraining(\n",
       "      (roberta): RobertaModel(\n",
       "        (embeddings): RobertaEmbeddings(\n",
       "          (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
       "          (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "          (token_type_embeddings): Embedding(1, 768)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (encoder): RobertaEncoder(\n",
       "          (layer): ModuleList(\n",
       "            (0-11): 12 x RobertaLayer(\n",
       "              (attention): RobertaAttention(\n",
       "                (self): RobertaSelfAttention(\n",
       "                  (query): Linear(\n",
       "                    in_features=768, out_features=768, bias=True\n",
       "                    (lora_dropout): ModuleDict(\n",
       "                      (default): Dropout(p=0.1, inplace=False)\n",
       "                    )\n",
       "                    (lora_A): ModuleDict(\n",
       "                      (default): Linear(in_features=768, out_features=8, bias=False)\n",
       "                    )\n",
       "                    (lora_B): ModuleDict(\n",
       "                      (default): Linear(in_features=8, out_features=768, bias=False)\n",
       "                    )\n",
       "                    (lora_embedding_A): ParameterDict()\n",
       "                    (lora_embedding_B): ParameterDict()\n",
       "                  )\n",
       "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (value): Linear(\n",
       "                    in_features=768, out_features=768, bias=True\n",
       "                    (lora_dropout): ModuleDict(\n",
       "                      (default): Dropout(p=0.1, inplace=False)\n",
       "                    )\n",
       "                    (lora_A): ModuleDict(\n",
       "                      (default): Linear(in_features=768, out_features=8, bias=False)\n",
       "                    )\n",
       "                    (lora_B): ModuleDict(\n",
       "                      (default): Linear(in_features=8, out_features=768, bias=False)\n",
       "                    )\n",
       "                    (lora_embedding_A): ParameterDict()\n",
       "                    (lora_embedding_B): ParameterDict()\n",
       "                  )\n",
       "                  (dropout): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (output): RobertaSelfOutput(\n",
       "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                  (dropout): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (intermediate): RobertaIntermediate(\n",
       "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "                (intermediate_act_fn): GELUActivation()\n",
       "              )\n",
       "              (output): RobertaOutput(\n",
       "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (lm_head): RobertaLMHead(\n",
       "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (decoder): Linear(in_features=768, out_features=50265, bias=True)\n",
       "      )\n",
       "      (seq_classifier): MeanSequenceClassifier(\n",
       "        (classifier): Linear(in_features=768, out_features=12, bias=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outputs:\n",
      " BaseModelOutputWithPoolingAndCrossAttentions(last_hidden_state=tensor([[[-0.0774,  0.1109, -0.0291,  ..., -0.0546, -0.0372, -0.0463],\n",
      "         [-0.0203, -0.0831,  0.2454,  ..., -0.0613,  0.1672, -0.1087],\n",
      "         [-0.0317, -0.0290,  0.0410,  ...,  0.0523, -0.1697, -0.0263],\n",
      "         ...,\n",
      "         [-0.0052,  0.3558, -0.0670,  ..., -0.1990,  0.0941,  0.0300],\n",
      "         [-0.0686,  0.1020, -0.0595,  ..., -0.0820, -0.0333, -0.0822],\n",
      "         [-0.0264,  0.0509,  0.0005,  ...,  0.1742, -0.0074, -0.0330]]],\n",
      "       grad_fn=<NativeLayerNormBackward0>), pooler_output=None, hidden_states=None, past_key_values=None, attentions=None, cross_attentions=None)\n",
      "prior to being sent to the classifier the shape of sequence output is: torch.Size([1, 23, 768]), and pooled output is: torch.Size([1, 768])\n"
     ]
    }
   ],
   "source": [
    "outputs = model(**tokenized, category_label = labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TransformerForPreTrainingOutput([('loss', tensor(0., grad_fn=<SumBackward0>)),\n",
       "                                 ('mlm_loss', None),\n",
       "                                 ('cls_loss',\n",
       "                                  tensor(0., grad_fn=<SumBackward0>)),\n",
       "                                 ('prediction_logits',\n",
       "                                  tensor([[[34.6068, -3.8174, 18.3210,  ...,  2.9154,  5.9354, 11.6600],\n",
       "                                           [ 5.3773, -3.3239, 18.0196,  ...,  1.6447,  3.2221,  6.7053],\n",
       "                                           [-2.3307, -4.8697,  6.7838,  ..., -5.5666, -5.9032, -1.2778],\n",
       "                                           ...,\n",
       "                                           [-0.1162, -3.9556, 11.1376,  ..., -1.6905, -2.2702,  1.9070],\n",
       "                                           [18.5936, -4.3268, 19.8805,  ...,  0.9715,  3.8395,  7.2003],\n",
       "                                           [14.5368, -4.1192, 31.6962,  ...,  0.1742, -1.7078,  9.5063]]],\n",
       "                                         grad_fn=<ViewBackward0>)),\n",
       "                                 ('seq_classifier_logits', None),\n",
       "                                 ('hidden_states', None),\n",
       "                                 ('attentions', None),\n",
       "                                 ('seq_embedding',\n",
       "                                  tensor([[-5.9754e-02,  7.4206e-02,  4.5147e-02, -4.2449e-02,  1.8819e-02,\n",
       "                                            7.5920e-02, -6.7188e-02,  9.2215e-02,  1.4937e-02, -6.3319e-02,\n",
       "                                            9.8665e-02,  2.6070e-03,  9.3113e-02,  1.0731e-02,  1.0605e-01,\n",
       "                                           -1.0677e-01,  2.4716e-01,  3.3009e-02, -5.7726e-02,  6.6471e-02,\n",
       "                                            7.3487e-02,  1.2560e-01,  1.9517e-02,  9.0952e-02, -9.4223e-02,\n",
       "                                            1.5818e-01,  2.2464e-01,  3.2895e-02, -5.0779e-02,  5.3394e-02,\n",
       "                                           -7.5024e-03, -8.2406e-02,  7.3417e-02,  5.5701e-02,  4.6876e-02,\n",
       "                                            1.1103e-02,  4.2419e-02,  5.5888e-02,  4.4134e-01, -1.2983e-02,\n",
       "                                            7.1491e-02,  2.8728e-01,  7.6572e-02,  2.6000e-02,  4.9299e-02,\n",
       "                                           -3.7280e-02, -1.3137e-01,  1.0966e-01,  3.1755e-02, -1.4510e-01,\n",
       "                                           -6.5202e-03, -5.7030e-02, -7.9607e-03, -9.8376e-02,  9.9634e-02,\n",
       "                                            2.6698e-02,  2.1440e-02,  5.8392e-02,  1.2817e-01, -3.4653e-02,\n",
       "                                           -3.8314e-02,  4.9890e-02, -4.5181e-02, -7.8525e-02, -1.4759e-02,\n",
       "                                           -9.7722e-02,  1.4383e-02,  3.5949e-02,  5.0757e-02,  2.8311e-02,\n",
       "                                            9.2586e-02, -1.4346e-01,  1.5130e-01, -7.2319e-02,  3.1861e-02,\n",
       "                                            2.2509e-01,  6.2805e-02, -6.2241e+00, -2.5778e-02,  1.1735e-01,\n",
       "                                            1.3772e-01,  3.2119e-02,  8.3490e-01, -5.1013e-02,  5.3194e-02,\n",
       "                                           -5.4322e-01,  1.3061e-01,  7.4769e-02,  1.6141e-01,  5.1128e-02,\n",
       "                                            1.0131e-01,  5.1096e-02,  1.7844e-01, -3.6701e-02,  8.5557e-02,\n",
       "                                            2.8347e-03, -1.2605e-01,  8.4369e-01, -4.3197e-02,  6.4165e-02,\n",
       "                                            5.2499e-02,  1.4140e-02, -8.6507e-02,  3.8288e-02, -1.4956e-01,\n",
       "                                            7.8371e-02, -1.5731e-01, -1.5108e-01,  1.7810e-01,  5.2379e-02,\n",
       "                                            4.2066e-03, -6.3457e-02, -9.1500e-02,  8.1967e-02,  4.6605e-02,\n",
       "                                           -2.4083e-01,  4.3605e-02,  1.0164e-01,  4.4692e-02,  3.8560e-01,\n",
       "                                           -1.0958e-01,  9.2389e-02,  1.8022e-01,  7.1880e-04,  1.9783e-01,\n",
       "                                            6.0883e-02, -1.5699e-01,  2.2881e-02,  4.6630e-02, -8.0405e-03,\n",
       "                                           -1.1372e-01, -4.5259e-01, -1.3014e-01,  1.8454e-01,  9.6171e-02,\n",
       "                                           -2.2783e-02,  6.0028e-02,  4.6523e-02, -6.2582e-02, -1.2225e-02,\n",
       "                                            4.7760e-02,  6.4631e-02,  4.2360e-02,  5.6241e-02, -1.0783e-01,\n",
       "                                            4.4484e-02, -3.2814e-02, -2.0470e-01, -1.6734e-01,  9.7559e-02,\n",
       "                                           -6.7421e-02,  1.9576e-01,  1.3395e-02,  7.7321e-02,  5.6004e-02,\n",
       "                                            3.1044e-01, -1.2087e-01,  7.2895e-03, -1.0987e-01,  3.7520e-01,\n",
       "                                            1.3037e-01,  1.9924e-02,  1.7830e-01,  7.7927e-02, -2.3270e-02,\n",
       "                                            1.1828e-01, -5.6880e-02, -5.5433e-02, -7.8442e-02,  8.9538e-02,\n",
       "                                           -1.1277e-01,  2.1028e-02, -2.2825e-02,  2.1960e-02, -1.8488e-01,\n",
       "                                           -9.2900e-02,  1.1563e-01,  2.5502e-02,  2.9175e-02, -4.7685e-02,\n",
       "                                           -5.4770e-02,  1.3664e-01, -1.1446e-01,  3.6377e-02, -1.5072e-01,\n",
       "                                            1.1551e-01,  1.5868e-02,  1.7034e-01, -1.3917e-01,  8.9481e-02,\n",
       "                                           -1.3629e-01, -7.6629e-02, -8.8742e-02,  1.0790e-01,  5.1182e-02,\n",
       "                                           -9.8846e-02,  8.2203e-02,  5.6817e-02,  2.0843e-01, -6.2295e-02,\n",
       "                                            4.2848e-02,  3.3163e-02,  2.4212e-01, -6.4651e-02,  4.3187e-01,\n",
       "                                            6.8212e-02,  4.8724e-02,  4.3491e-02, -1.0686e-02, -1.3354e-02,\n",
       "                                           -9.8964e-02,  1.1530e-01, -2.6408e-02,  2.1722e-01, -3.7403e-02,\n",
       "                                            1.1815e-01, -3.7898e-02, -1.2505e+00,  1.3898e-01,  4.1488e-01,\n",
       "                                            4.7404e-02, -7.2917e-02, -8.0805e-02, -2.8339e-01, -4.9286e-02,\n",
       "                                           -1.2949e-01, -3.4545e-02, -2.3930e-02,  1.2426e-02,  1.8562e-01,\n",
       "                                            3.1208e-02, -6.0512e-02,  2.0955e-02,  9.6498e-02,  1.1337e-01,\n",
       "                                           -1.9296e-01, -1.2094e-01,  7.3128e-02, -1.3610e-02, -3.8954e-02,\n",
       "                                           -3.1560e-01,  5.7356e-02, -7.6113e-02,  1.5581e-01,  2.5433e-02,\n",
       "                                            1.3118e-01, -8.2911e-04,  6.8449e-01,  1.2853e-01,  5.8261e-02,\n",
       "                                            1.5627e-01, -1.7484e-01, -5.7547e-02, -1.3934e-01, -6.4943e-02,\n",
       "                                           -2.2674e-02, -9.4791e-02,  7.3121e-02, -2.1076e-01,  2.7578e-02,\n",
       "                                           -4.8730e-02, -8.9295e-02,  1.6159e-01,  1.6985e-02,  2.8069e-03,\n",
       "                                            2.6914e-01,  2.9959e-02,  1.0099e-01,  6.6862e-02,  1.0943e-02,\n",
       "                                            1.1046e-01, -2.3229e-01, -3.4958e-02,  7.8050e-02,  1.8391e-02,\n",
       "                                            6.4648e-02,  1.9118e-01, -1.5583e-02,  1.9487e-01,  1.0064e-01,\n",
       "                                            1.2135e-01,  3.9519e-02, -2.0961e-01, -1.6129e-01,  1.0132e-01,\n",
       "                                            4.7850e-02, -7.0394e-01,  1.3723e-02, -4.2757e-02,  7.1175e-02,\n",
       "                                            1.4495e-01,  1.0561e-02, -8.4657e-02,  1.0408e-02, -7.7156e-02,\n",
       "                                           -1.2168e-01,  1.1259e-01, -1.7682e-01,  1.6880e-02,  5.6827e-02,\n",
       "                                            1.4256e-01,  2.2969e-02,  3.1644e-01,  2.9408e-02, -4.2558e-02,\n",
       "                                           -7.7740e-02,  7.1798e-02,  1.3116e-02, -8.1023e-02, -1.9643e-02,\n",
       "                                           -1.3144e-01,  1.1123e-02,  4.9419e-02,  1.2308e-01,  2.2893e-02,\n",
       "                                            2.6529e-02,  2.7598e-01, -7.8471e-02, -1.1946e-02, -8.5721e-02,\n",
       "                                            3.8177e-03, -3.5603e-02, -1.2497e-01, -1.2055e-02, -4.3321e-02,\n",
       "                                            6.2689e-03, -8.6924e-02,  4.5358e-02,  2.1004e-01,  3.9555e-02,\n",
       "                                            5.5172e-01,  1.0586e+00,  1.2433e-01,  1.4651e-01,  9.4752e-02,\n",
       "                                            4.2478e-02,  4.4115e-02,  1.1896e-03,  1.0369e-01,  3.7411e-02,\n",
       "                                           -1.3770e-01, -3.5525e-02, -2.1413e-01,  8.5779e-02,  1.0054e-02,\n",
       "                                            9.4100e-02, -6.3304e-03, -8.8143e-02,  1.7046e-01, -2.1809e-01,\n",
       "                                           -1.2220e-01, -9.2264e-02, -4.9813e-02,  4.4414e-02,  5.2546e-03,\n",
       "                                            7.6702e-02, -2.5921e-02, -4.3300e-02, -2.3930e-02,  1.0523e-01,\n",
       "                                            9.7564e-02,  1.4817e-01,  1.4764e-01, -2.3232e-01, -1.1881e-01,\n",
       "                                           -2.2182e-02,  3.1724e-02, -3.2129e-02, -2.6057e-02, -2.7622e-02,\n",
       "                                            1.7425e-01, -1.9523e-03,  4.5243e-02,  5.4856e-03, -1.0184e-01,\n",
       "                                            1.8295e-02,  3.0168e-02, -1.0758e-01, -3.2862e-02,  2.5906e-02,\n",
       "                                            1.1574e-02,  2.2728e-02, -2.3949e-02, -3.9516e-02,  1.4243e-01,\n",
       "                                           -2.9968e-02,  6.7377e-02, -1.8076e-02,  3.2598e-02, -3.6104e-02,\n",
       "                                            9.7431e-02,  5.4128e-02, -1.0455e-02,  1.0405e-01, -3.7575e-02,\n",
       "                                           -2.7487e-02,  2.8010e-01,  3.1408e-02,  1.6420e-01, -1.0456e-01,\n",
       "                                           -3.5415e-02,  2.0506e-01,  3.1450e-02,  1.0995e-01,  1.5007e-02,\n",
       "                                            1.0327e-01, -2.8716e-02, -8.3210e-02, -1.0365e-01,  9.8235e-02,\n",
       "                                            5.9004e-02, -4.1462e-02, -1.1399e-03,  1.3327e-01,  3.3468e-02,\n",
       "                                            1.0878e-03,  2.6719e-01, -2.0548e-01, -1.1774e-01,  1.7111e-01,\n",
       "                                           -8.5448e-02, -4.1562e-02,  1.1011e-01, -1.4894e-01,  3.0707e-01,\n",
       "                                           -6.0577e-02,  1.3980e-01, -1.3754e-01,  1.4438e-02, -1.1351e-01,\n",
       "                                           -1.0874e-01,  7.8714e-02,  1.3752e-01,  2.4711e-02,  1.0884e-01,\n",
       "                                            2.2980e-02,  1.7501e-01, -5.7882e-02, -7.4025e-03, -6.2475e-02,\n",
       "                                            9.5137e-02, -7.3510e-02,  2.6304e-03,  1.2472e-02,  1.4420e-01,\n",
       "                                            1.5212e-01,  1.3036e-01,  5.9588e-02,  1.6467e-01, -9.2987e-02,\n",
       "                                            5.2277e-02,  4.2558e-02, -2.1802e-01, -9.5752e-01,  1.0131e-01,\n",
       "                                            1.0657e-01,  1.5328e-01, -1.4325e-01, -2.4975e-01,  4.8015e-02,\n",
       "                                           -2.0855e-02,  6.6960e-02, -3.0065e-02,  9.9664e-02, -4.7914e-02,\n",
       "                                           -1.5556e-02, -1.1119e-01,  7.8119e-02, -7.8359e-02,  3.4105e-02,\n",
       "                                            1.7426e-02,  2.8416e-03, -4.3690e-03, -3.4217e-01,  8.3493e-03,\n",
       "                                            8.0636e-02,  3.7606e-02,  9.4899e-02,  1.1289e-01,  1.3049e-01,\n",
       "                                           -6.6600e-02,  1.6504e-01, -3.2018e-02,  7.8615e-02, -8.9749e-02,\n",
       "                                           -1.7226e-02, -4.4928e-02, -7.9761e-02,  1.6206e-01,  7.3801e-03,\n",
       "                                            4.7605e-02,  3.1324e-02, -4.8855e-02,  1.7549e-01,  1.5344e-01,\n",
       "                                           -2.4914e-03, -6.6688e-01,  1.4043e-01, -1.2922e-01, -3.7521e-02,\n",
       "                                           -5.2289e-02,  7.7664e-02,  4.6133e-03, -8.7735e-02,  2.9240e-02,\n",
       "                                            2.1214e-01,  2.4464e-02, -5.5631e-02,  2.9680e-02,  5.9650e-02,\n",
       "                                            4.2883e-02, -7.4116e-02,  3.4548e-02, -4.0620e-02,  5.7114e-02,\n",
       "                                            6.9359e-02, -7.0937e-02, -8.1102e-02, -1.4166e-01,  1.1675e-01,\n",
       "                                            1.2963e-01,  9.5179e-02, -1.4473e-02,  1.1490e-01, -1.9609e-02,\n",
       "                                            3.5935e-02,  1.0200e-01, -2.0399e-02,  1.6677e-01, -8.6981e-02,\n",
       "                                            1.0847e-01, -2.2365e-01,  1.5816e-01,  7.2884e-02, -1.3069e-02,\n",
       "                                           -1.3113e-02, -6.3889e-02, -1.4880e-01,  8.0708e-02,  2.7536e-02,\n",
       "                                            5.9436e-02,  6.7150e-02, -2.2312e-02,  8.6834e-03, -1.4368e-02,\n",
       "                                           -8.4054e-03, -2.0781e-02, -6.8577e-02, -9.3977e-02,  8.2147e-02,\n",
       "                                            1.3129e-01, -1.1927e-01,  4.9832e-02, -3.6077e-02, -5.1689e-03,\n",
       "                                           -4.7681e-02, -5.5619e-02,  1.9980e-01,  6.5102e-02, -4.1852e-02,\n",
       "                                            4.0779e-02, -1.8472e-01, -3.6271e-02,  3.1932e-02,  2.6812e-02,\n",
       "                                           -4.2401e-02, -9.0677e-03,  1.9299e-02, -2.2110e-02,  2.9061e-01,\n",
       "                                            2.0649e-01,  6.5162e-02, -8.3641e-03, -1.0552e-01,  4.9883e-02,\n",
       "                                            1.5323e-01,  4.4491e-02,  1.7606e-01, -9.3598e-02, -6.0315e-03,\n",
       "                                           -7.4142e-02, -1.3386e-01,  4.5198e-02,  1.2969e-01,  2.5797e-02,\n",
       "                                            1.1986e-01, -2.1003e-01, -1.4563e-01,  1.0275e+01, -1.6316e-02,\n",
       "                                           -3.8884e-02,  1.7097e-01, -2.4442e-02,  7.9343e-03, -4.3389e-02,\n",
       "                                            3.6213e-03,  1.4256e-03, -1.6150e-02, -3.2025e-03,  1.4135e-01,\n",
       "                                            2.4230e-02, -2.9383e-02, -2.6419e-02, -3.1913e-03, -6.3610e-02,\n",
       "                                           -4.3258e-02, -6.2146e-02, -4.8358e-02, -6.7613e-02, -5.2437e-02,\n",
       "                                            9.7131e-03,  5.3610e-01, -3.2793e-02, -2.3390e-02,  1.9216e-02,\n",
       "                                            5.5993e-02, -7.6489e-02, -4.9855e-03, -2.1130e-02, -6.0663e-02,\n",
       "                                           -8.0009e-02,  2.4672e-03,  1.0643e-01,  7.3361e-02,  1.5731e-01,\n",
       "                                            1.4268e-01, -7.8152e-02,  5.3839e-02,  5.5750e-02, -5.9867e-02,\n",
       "                                            2.5334e-02, -2.8995e-02,  4.8505e-02,  1.1113e-02,  1.2020e-01,\n",
       "                                            2.9183e-02,  1.3493e-01, -2.3881e-02,  2.6631e-02, -2.9855e-02,\n",
       "                                            1.0288e-01,  1.5320e-02, -1.7125e-02,  2.3948e-03, -1.5526e-01,\n",
       "                                           -1.5954e-02, -2.4937e-02, -1.0443e-01, -5.1334e-02,  2.4780e-02,\n",
       "                                            5.6626e-03,  3.6132e-01,  1.1348e-01,  8.6868e-02,  2.2040e-02,\n",
       "                                            2.7000e-02,  1.8567e-01, -1.0824e-01, -5.8586e-02, -5.8665e-02,\n",
       "                                           -1.9154e-02, -1.1214e-02,  3.2790e-02,  5.9120e-02,  1.1628e-01,\n",
       "                                            3.9403e-02, -1.2994e-01, -2.7933e-01,  2.5337e-02,  1.8436e-02,\n",
       "                                            1.3180e-01, -2.3994e-02,  2.4676e-01,  1.3247e-01,  1.1797e-01,\n",
       "                                           -3.2502e-02,  1.7733e-01,  1.5736e-01, -1.2475e-01,  1.9732e-01,\n",
       "                                           -3.1159e-02,  1.4255e-02,  7.8115e-02, -1.0690e-01,  1.5778e-01,\n",
       "                                           -4.9785e-02,  1.7728e-01, -7.1136e-02, -7.8996e-02,  1.2944e-01,\n",
       "                                            2.3042e-02, -3.4142e-02,  1.4138e-02, -2.5522e-02, -1.9633e-02,\n",
       "                                           -1.8396e-01,  8.3163e-02,  2.1852e-02,  5.5883e-02, -4.7973e-02,\n",
       "                                            1.0989e-01, -7.4357e-02, -6.6166e-03, -5.1651e-02, -8.7151e-03,\n",
       "                                            1.2577e-01,  8.1890e-03, -1.1232e-01, -3.9789e-02,  6.3847e-03,\n",
       "                                            2.9048e-02,  2.0231e-02, -3.3314e-02,  2.6678e-02,  6.4667e-02,\n",
       "                                           -1.0783e-01, -3.0814e-03, -3.7173e-02, -1.0779e-02,  1.0135e-01,\n",
       "                                            2.8200e-01, -1.6009e-01,  7.3303e-02, -6.6826e-02,  1.4403e-02,\n",
       "                                            8.5252e-02,  2.2290e-01, -6.5377e-02, -8.5606e-02, -2.6649e-01,\n",
       "                                            1.0093e-02, -4.4694e-01, -1.1187e-01,  7.5399e-02,  1.0448e-01,\n",
       "                                            8.6801e-02,  7.2997e-02, -9.6421e-02,  9.4571e-03, -3.8442e-02,\n",
       "                                            1.4430e-01, -1.0510e-01, -5.8182e-02,  6.2563e-02,  9.2547e-02,\n",
       "                                            1.4296e-01, -7.0589e-03,  2.7730e-02, -7.6874e-03, -7.8169e-01,\n",
       "                                            9.1165e-02, -1.2792e-01, -1.0156e-02,  4.6845e-02, -1.6944e-01,\n",
       "                                           -1.4431e-01,  4.3963e-02,  6.5352e-03, -7.5175e-02, -1.8411e-02,\n",
       "                                            4.8046e-02, -6.4041e-02,  7.8160e-02,  1.8138e-01, -1.4350e-01,\n",
       "                                            4.4226e-02,  6.1405e-02, -1.1118e-01]], grad_fn=<DivBackward0>))])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "normal_outputs = normal_model(**tokenized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BaseModelOutputWithPoolingAndCrossAttentions(last_hidden_state=tensor([[[-0.0774,  0.1109, -0.0291,  ..., -0.0546, -0.0372, -0.0463],\n",
       "         [-0.0203, -0.0831,  0.2454,  ..., -0.0613,  0.1672, -0.1087],\n",
       "         [-0.0317, -0.0290,  0.0410,  ...,  0.0523, -0.1697, -0.0263],\n",
       "         ...,\n",
       "         [-0.0052,  0.3558, -0.0670,  ..., -0.1990,  0.0941,  0.0300],\n",
       "         [-0.0686,  0.1020, -0.0595,  ..., -0.0820, -0.0333, -0.0822],\n",
       "         [-0.0264,  0.0509,  0.0005,  ...,  0.1742, -0.0074, -0.0330]]],\n",
       "       grad_fn=<NativeLayerNormBackward0>), pooler_output=tensor([[ 1.2005e-02, -2.2570e-01, -2.0211e-01, -8.3373e-02,  1.5201e-01,\n",
       "          2.0418e-01,  2.6802e-01, -5.5586e-02, -9.9229e-02, -1.8181e-01,\n",
       "          2.8494e-01,  5.7336e-03, -1.2715e-01,  1.4829e-01, -1.4396e-01,\n",
       "          4.7950e-01,  1.9732e-01, -5.0816e-01,  3.4845e-02, -2.8383e-02,\n",
       "         -2.7479e-01,  7.1890e-02,  4.8310e-01,  3.5491e-01,  1.0504e-01,\n",
       "          4.9484e-02, -1.5675e-01, -2.3135e-02,  1.6638e-01,  2.6402e-01,\n",
       "          2.8848e-01,  3.4615e-02,  1.2710e-01,  2.6789e-01, -2.5443e-01,\n",
       "          6.4168e-02, -3.4002e-01, -3.9734e-03,  3.0277e-01, -2.2120e-01,\n",
       "         -8.9604e-02,  1.7832e-01,  2.0380e-01, -1.8134e-01, -9.8838e-02,\n",
       "          4.1078e-01,  2.5500e-01,  3.7739e-02, -1.4387e-01, -1.1111e-01,\n",
       "         -3.4242e-01,  3.5703e-01,  3.1444e-01,  1.9926e-01, -3.8732e-02,\n",
       "          4.5289e-02, -1.0941e-01,  2.7989e-01, -7.1081e-02, -1.0282e-01,\n",
       "         -1.2092e-01, -2.3947e-01,  8.5019e-03, -7.4719e-02,  3.3276e-02,\n",
       "         -1.5796e-01,  1.0640e-01, -1.8000e-01, -1.3936e-01,  9.7726e-03,\n",
       "         -1.3304e-01,  1.3954e-01,  1.9823e-01, -3.1144e-01, -3.0229e-01,\n",
       "          5.8515e-02, -6.2680e-01, -1.1852e-01,  3.4339e-01,  4.3589e-01,\n",
       "         -8.3398e-02,  2.2404e-01,  3.3824e-02,  2.2644e-01, -5.6655e-03,\n",
       "         -4.4142e-02, -3.2314e-02, -1.2779e-01,  1.5293e-01,  2.4752e-01,\n",
       "         -2.1375e-01, -4.0772e-01,  7.5477e-02,  2.7730e-02, -7.0166e-02,\n",
       "          3.5027e-02, -2.1179e-02, -7.7342e-02, -2.1309e-01, -2.0622e-01,\n",
       "          9.7458e-02, -2.4458e-01, -1.6457e-01,  2.7591e-01,  1.0803e-02,\n",
       "         -1.6939e-01, -2.1190e-02,  3.0394e-01,  5.7626e-02, -1.1333e-01,\n",
       "         -2.0025e-01,  4.5111e-01,  3.4975e-01, -3.9329e-02,  2.0833e-02,\n",
       "          1.6139e-01,  1.7957e-01, -2.9269e-01,  4.5563e-01, -3.5872e-01,\n",
       "          1.2518e-02, -7.7494e-02,  1.2982e-01,  1.7702e-01, -2.1263e-01,\n",
       "          2.8554e-01,  1.3834e-01,  2.9926e-01,  1.8612e-01,  1.4283e-01,\n",
       "         -4.4945e-02,  1.3455e-01, -1.2315e-01,  1.3210e-01,  2.4214e-01,\n",
       "          1.0830e-01,  6.1309e-03, -3.4527e-01, -2.4583e-01,  2.6949e-01,\n",
       "          3.3996e-01,  1.6444e-01, -4.4124e-02,  2.0068e-01,  1.4254e-01,\n",
       "          2.3481e-01,  1.3416e-01, -4.1819e-01,  4.3696e-02,  3.6909e-01,\n",
       "          1.0802e-01,  1.5064e-01, -1.2984e-01, -2.9288e-01, -2.7997e-01,\n",
       "         -1.1469e-01,  5.6138e-02, -3.4279e-01, -1.1733e-01,  3.7063e-01,\n",
       "          6.4810e-02, -5.1423e-02, -1.9301e-01, -2.1375e-01, -2.0167e-02,\n",
       "         -1.6553e-01,  2.8041e-02,  1.0330e-01, -3.7795e-02, -4.5209e-01,\n",
       "         -1.4684e-01, -5.3824e-01, -1.0347e-01,  2.1086e-01, -3.3834e-01,\n",
       "          2.8867e-01, -2.9506e-01,  8.7871e-02,  4.2658e-01,  4.1503e-02,\n",
       "          3.0532e-03, -2.5894e-01, -1.3195e-02,  7.0706e-02,  3.0226e-01,\n",
       "          2.9589e-01, -4.2344e-01,  1.2546e-01,  1.2644e-01,  2.8571e-01,\n",
       "          1.0558e-01, -7.6469e-02, -1.1786e-01,  1.4737e-01, -2.1334e-01,\n",
       "          1.7838e-01, -2.3085e-01,  1.7495e-01, -2.6816e-01, -2.2704e-01,\n",
       "          3.4011e-01, -4.2732e-01, -4.3742e-02,  8.3735e-02,  2.5268e-01,\n",
       "          1.4804e-03, -6.3717e-02, -1.3597e-01,  1.6780e-01,  1.6855e-01,\n",
       "          1.2944e-01, -4.1360e-01,  3.2357e-01, -2.3738e-02, -2.4692e-02,\n",
       "         -4.8883e-02,  1.7796e-01,  2.5228e-01,  9.9629e-02, -3.9350e-01,\n",
       "         -1.3917e-01,  1.4753e-01,  3.0605e-01, -2.3908e-01,  1.9529e-01,\n",
       "         -3.2940e-01, -4.2314e-01, -9.7896e-02,  2.3310e-01,  2.2080e-01,\n",
       "          1.6665e-01, -2.8935e-01,  1.7402e-01, -1.4047e-01, -4.3608e-01,\n",
       "         -3.8584e-01, -1.3508e-01,  2.3791e-01,  1.6904e-01,  1.8611e-01,\n",
       "          2.5927e-01,  2.3655e-02,  1.5592e-01,  1.7799e-01,  1.8030e-01,\n",
       "         -1.5012e-01,  1.7746e-01, -3.7547e-01, -3.1651e-02, -3.2364e-01,\n",
       "         -2.2193e-01, -2.4299e-01,  4.4442e-01, -2.6601e-01,  2.3730e-01,\n",
       "          4.3297e-01, -3.3021e-01, -1.1300e-01,  1.4804e-01,  1.5510e-01,\n",
       "          7.5141e-02, -1.2233e-01,  2.0429e-01,  2.2973e-01, -8.8248e-02,\n",
       "          2.9266e-01, -2.6727e-02,  2.9649e-01,  1.5990e-01,  5.5668e-02,\n",
       "          1.1314e-01,  1.2251e-01, -1.2824e-01,  1.0264e-01, -5.3174e-03,\n",
       "         -4.0875e-02, -2.5941e-01, -1.4126e-01,  2.2722e-01, -7.6122e-02,\n",
       "          3.1088e-02, -1.4524e-01, -5.1860e-02,  4.4793e-03,  4.2067e-01,\n",
       "         -3.5123e-01,  2.7808e-01,  9.8744e-02,  1.7008e-01, -2.4187e-01,\n",
       "         -2.3568e-01,  9.7321e-02,  1.9816e-01, -4.4313e-01,  2.5818e-02,\n",
       "          1.4546e-01,  9.7604e-02,  2.2847e-01,  2.8304e-01, -4.7612e-03,\n",
       "         -1.5027e-01,  5.4029e-01, -1.5859e-01, -1.0770e-01,  2.8210e-01,\n",
       "         -2.7768e-01, -2.6966e-01,  2.5710e-01, -1.5670e-02,  3.4369e-01,\n",
       "          1.3322e-01,  4.2185e-02,  6.4107e-02, -5.9904e-01,  6.5129e-02,\n",
       "         -4.7924e-01, -3.3511e-02,  4.8295e-02, -8.3160e-02, -2.0506e-01,\n",
       "          1.9392e-01,  2.8993e-01, -2.3356e-01, -7.0891e-03,  2.1827e-01,\n",
       "          5.0150e-02, -1.0280e-01,  4.8885e-01,  2.4740e-04,  2.4622e-01,\n",
       "         -6.7891e-02,  2.6135e-01, -2.2763e-01,  2.7508e-01, -2.8400e-01,\n",
       "         -1.2680e-01,  5.8685e-02,  8.1860e-02,  6.3738e-02, -6.5099e-02,\n",
       "         -3.5210e-01,  2.4637e-01,  8.1327e-04, -5.9193e-02, -5.8233e-02,\n",
       "          1.3492e-01, -3.1712e-02,  5.5610e-02,  6.7270e-02,  3.1768e-01,\n",
       "          2.2220e-01, -4.0067e-02, -3.8411e-01, -7.7362e-02, -1.1643e-01,\n",
       "          7.3473e-02,  5.5106e-02,  3.4929e-02,  4.8287e-01, -7.2591e-02,\n",
       "          9.4241e-03, -1.2919e-01,  2.7668e-01,  2.3062e-01,  1.6021e-01,\n",
       "          1.6589e-01,  6.0873e-02,  1.9229e-01, -3.3307e-02,  3.4758e-03,\n",
       "         -1.8026e-01, -2.3995e-01, -2.8846e-01,  2.4193e-01, -2.7062e-01,\n",
       "         -1.7516e-01,  1.4519e-01,  1.7526e-01, -1.3689e-01,  1.6027e-01,\n",
       "          3.3098e-01,  1.0521e-01, -1.5880e-01,  3.0591e-01, -7.9880e-02,\n",
       "          8.1141e-02,  3.1819e-01, -6.8896e-02,  1.8724e-01,  5.3268e-01,\n",
       "          2.3839e-01, -4.0336e-01, -4.9953e-02, -2.3347e-01,  9.4634e-03,\n",
       "          2.3957e-01, -1.1967e-01,  1.8102e-01,  3.6636e-01,  3.1711e-01,\n",
       "          4.8397e-01, -1.6591e-02, -1.2693e-01,  1.1980e-01,  2.3795e-01,\n",
       "          3.0628e-02, -2.1337e-01, -1.6172e-01,  2.6921e-01,  7.1407e-02,\n",
       "         -1.6155e-01, -3.6852e-03, -1.4894e-01,  6.7894e-02, -1.6848e-01,\n",
       "         -4.2542e-01,  6.2811e-02,  1.7323e-01, -5.2307e-01,  1.4898e-01,\n",
       "         -3.2173e-01,  3.6161e-02, -2.4666e-01,  2.2130e-01, -2.3720e-01,\n",
       "         -1.3666e-01,  4.1884e-01, -5.3342e-02,  3.3080e-02, -1.9063e-01,\n",
       "         -1.4578e-01,  3.6990e-02, -3.2242e-03, -7.4349e-02, -1.6578e-02,\n",
       "          3.4678e-01, -1.7591e-01,  5.7225e-02, -4.1639e-03,  2.2219e-01,\n",
       "         -6.1103e-02,  1.9209e-01, -1.0023e-02, -1.6365e-01, -3.8661e-01,\n",
       "          1.2833e-01, -1.9841e-01, -4.3697e-01, -4.0948e-01,  3.9968e-01,\n",
       "         -1.4842e-01, -2.7929e-01, -2.2643e-01, -2.6446e-01,  7.6072e-02,\n",
       "          2.1316e-01,  4.6463e-01, -3.8964e-01, -4.6214e-02,  4.9384e-01,\n",
       "         -6.1525e-02, -2.0408e-01,  2.8400e-01,  2.1919e-01, -3.3826e-01,\n",
       "          3.5396e-01,  2.7267e-01, -4.8533e-02,  2.4074e-02,  5.1799e-01,\n",
       "          1.3151e-01,  2.0971e-01, -1.5855e-01,  4.8370e-01, -2.5668e-01,\n",
       "          3.2809e-01, -1.3793e-01, -1.7943e-01, -2.5543e-01, -2.5294e-02,\n",
       "          3.5653e-01,  2.1770e-01, -4.5066e-01, -1.1703e-01,  5.8776e-02,\n",
       "          3.1868e-01, -4.0791e-01, -5.8804e-02,  2.0185e-02, -3.7797e-01,\n",
       "          1.3552e-01,  1.1185e-01,  2.2836e-01, -4.3088e-01, -4.5598e-02,\n",
       "          4.0379e-01, -3.3991e-01,  1.5701e-01,  3.0245e-01,  9.3205e-02,\n",
       "          3.6385e-01, -7.1426e-02,  1.7614e-02,  5.6519e-02, -2.4165e-01,\n",
       "         -6.1322e-03,  1.1615e-01,  5.7597e-01,  1.3548e-01, -4.0537e-01,\n",
       "          1.0509e-01,  2.6136e-01, -1.9167e-01,  3.2888e-01, -8.0328e-02,\n",
       "         -3.6505e-03,  2.6111e-01, -4.1829e-02,  1.5811e-01, -9.7712e-02,\n",
       "         -2.6058e-01, -3.2902e-01,  4.2767e-01, -2.2894e-01, -1.0068e-01,\n",
       "         -1.8484e-01, -8.3686e-02, -1.9170e-01,  4.4675e-02, -3.9440e-01,\n",
       "          3.5747e-01,  1.5618e-01, -1.9892e-01, -1.1067e-01, -1.1215e-01,\n",
       "         -1.7505e-01, -2.1020e-01, -2.7810e-01,  4.1371e-01, -1.7038e-01,\n",
       "         -4.9472e-01,  2.8267e-01, -8.8003e-03,  3.6536e-01,  4.7264e-02,\n",
       "          1.1504e-01, -8.2294e-02,  1.5195e-01,  9.9983e-02, -9.2830e-02,\n",
       "          2.8992e-01,  6.2516e-02, -5.9829e-01, -1.2400e-01, -2.3809e-01,\n",
       "          9.6508e-02,  2.5229e-01, -3.8897e-01,  1.2476e-02,  1.5317e-02,\n",
       "          2.0366e-01,  3.9176e-02, -1.3407e-01, -9.2585e-02,  3.9839e-01,\n",
       "          2.4580e-01,  2.7585e-01,  1.2628e-01,  2.1180e-01, -3.2878e-02,\n",
       "         -3.6962e-01,  1.4223e-02,  1.0496e-01, -2.1884e-01,  4.6946e-01,\n",
       "         -1.2797e-01, -3.7472e-01, -7.6239e-02,  3.9041e-01,  7.9767e-02,\n",
       "         -4.1299e-02, -4.7298e-02,  2.2786e-01,  1.6239e-01, -1.3583e-01,\n",
       "          2.2190e-01,  4.3487e-03, -1.5223e-01, -1.1869e-01,  1.0595e-01,\n",
       "         -2.2097e-01,  4.1652e-02, -1.5352e-01, -2.4704e-02, -2.1012e-01,\n",
       "          1.8379e-02, -1.9639e-01,  2.9524e-01, -3.3480e-01,  1.2368e-01,\n",
       "          3.0399e-02,  3.2263e-01, -3.7036e-01, -1.8510e-01, -3.9789e-02,\n",
       "          2.0962e-01,  2.7165e-01,  3.6739e-01,  1.6539e-02,  6.0088e-02,\n",
       "         -1.8615e-01, -2.7918e-01,  5.8234e-02, -2.2783e-01,  1.3743e-01,\n",
       "          8.3470e-02,  2.5779e-01, -3.0907e-01, -1.9629e-01,  2.1576e-01,\n",
       "         -4.9692e-02, -1.5943e-01,  4.6451e-01,  2.4743e-01,  1.8615e-01,\n",
       "          1.1295e-04,  2.2150e-01,  3.1411e-02, -1.5994e-01, -1.2648e-01,\n",
       "         -2.9665e-01,  8.3447e-02, -1.1841e-01, -4.9905e-02, -6.4714e-02,\n",
       "         -1.2205e-01, -2.3581e-01, -1.6372e-01,  1.4741e-01,  1.0977e-01,\n",
       "          3.5198e-02, -8.4213e-02, -3.5748e-02, -2.9533e-01,  3.3011e-01,\n",
       "          1.4157e-02,  7.8516e-02, -7.1973e-02,  9.5984e-02, -1.6156e-01,\n",
       "          2.3571e-01,  2.2239e-01,  9.2169e-02, -2.1006e-01, -5.6451e-02,\n",
       "         -3.3523e-01, -3.5193e-01,  3.1691e-02,  1.5460e-01,  1.6226e-01,\n",
       "         -1.0314e-01, -2.7386e-01,  9.1640e-03, -1.1398e-01,  1.8031e-01,\n",
       "          3.3357e-03, -1.8172e-01, -1.2229e-01, -7.8058e-02, -2.2020e-02,\n",
       "          7.2352e-02, -2.1827e-01, -1.8761e-01, -1.1733e-01, -9.0360e-02,\n",
       "         -7.3143e-02,  3.3662e-01, -7.4432e-02,  3.1101e-01, -1.6856e-01,\n",
       "          1.4349e-02, -1.9989e-01,  1.1270e-01, -8.9342e-02,  8.2013e-02,\n",
       "          3.0492e-01, -4.5915e-01, -1.5836e-01, -4.4251e-02, -1.9290e-01,\n",
       "         -1.5737e-01, -8.7834e-02, -3.5396e-02,  2.0191e-01, -3.7025e-01,\n",
       "          2.0985e-01, -1.0455e-01,  2.0098e-01, -7.1988e-02, -2.5779e-01,\n",
       "         -1.6326e-01,  2.2498e-02,  2.7162e-01, -3.3461e-01, -2.6459e-01,\n",
       "         -2.7924e-01, -1.0162e-01, -1.0560e-01, -2.6645e-01,  4.6132e-01,\n",
       "         -1.4508e-01, -6.4834e-02,  1.1682e-02,  4.2982e-01,  2.1031e-01,\n",
       "          1.7139e-01,  2.1449e-01, -4.9470e-03,  3.5724e-02,  1.2037e-01,\n",
       "         -4.9743e-01,  2.9316e-01, -2.7368e-01, -1.4775e-01, -3.4178e-03,\n",
       "          1.3630e-01, -4.8721e-02,  5.7156e-02, -1.6904e-01, -9.8420e-02,\n",
       "          2.2072e-01, -3.8550e-01, -2.1358e-02,  2.8431e-01,  1.4816e-01,\n",
       "         -2.8950e-01,  1.5879e-02,  1.1838e-01,  3.7603e-01,  6.5979e-02,\n",
       "         -2.3637e-01,  1.5375e-01, -3.6598e-01, -4.0773e-02, -1.9507e-01,\n",
       "         -3.1533e-01,  1.8113e-01, -1.0594e-01,  6.7843e-02, -7.8646e-02,\n",
       "         -2.9845e-01,  1.8226e-01, -4.8421e-02, -5.6216e-02,  4.4068e-01,\n",
       "          3.0869e-02, -1.1542e-01,  1.7110e-01,  6.4331e-03,  2.7213e-02,\n",
       "         -1.2013e-01,  2.9470e-01,  2.3173e-01, -3.1487e-01,  8.4362e-02,\n",
       "         -1.7747e-01, -4.5279e-02, -1.0782e-01]], grad_fn=<TanhBackward0>), hidden_states=None, past_key_values=None, attentions=None, cross_attentions=None)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normal_outputs"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now just need to ensure can batch data properly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_function(examples):\n",
    "    '''\n",
    "    Function to return a tokenized version of the input text\n",
    "\n",
    "    args:\n",
    "        examples: datasets object obtained via load_datasets. \n",
    "\n",
    "    returns:\n",
    "        dictionary of tokenized inputs with appropriate input_ids, attention_mask etc.\n",
    "    '''\n",
    "    return tokenizer(examples[\"TEXT\"], truncation=True, padding = True)\n",
    "\n",
    "def preprocess_function(examples):\n",
    "    \n",
    "    examples['labels'] = examples['input_ids'].copy()\n",
    "    return examples\n",
    "    \n",
    "\n",
    "def group_texts(tokenized_examples, block_size = 512):\n",
    "        '''\n",
    "        Function to concatenate all texts together then split the result into smaller chunks of a specified block_size\n",
    "\n",
    "        args:\n",
    "            examples: tokenized dataset produced by the tokenizer_function\n",
    "            block_size: int -> the chunk or block_size to divide the full concatenated text into\n",
    "        '''\n",
    "        examples = tokenized_examples.copy()\n",
    "        concatenated_examples = {k: sum(examples[k], []) for k in examples.keys()}\n",
    "        total_length = len(concatenated_examples[list(examples.keys())[0]])\n",
    "        # can use the following line to cut off tails\n",
    "        total_length = (total_length // block_size) * block_size\n",
    "        result = {\n",
    "            k: [t[i:i+block_size] for i in range(0,total_length, block_size)]\n",
    "            for k, t in concatenated_examples.items()\n",
    "        }\n",
    "        # for both causal and masked language modelling the \"right shift\" of input text is done by the model internally. Thus for now, labels=input_ids\n",
    "        result['labels'] = result['input_ids'].copy()\n",
    "        \n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subsample the dataset\n",
    "dataset[\"train\"] = dataset[\"train\"].select(range(1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['TEXT', 'CATEGORY', 'category_label'],\n",
       "        num_rows: 1000\n",
       "    })\n",
       "    valid: Dataset({\n",
       "        features: ['TEXT', 'CATEGORY', 'category_label'],\n",
       "        num_rows: 1000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /mnt/sdc/niallt/.cache/csv/default-e82d422e95c8b033/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1/cache-754901f8e2dae3bb.arrow\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca0f73fe13aa4210b3976ec9ebd25e3e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sentence1_key = \"TEXT\"\n",
    "\n",
    "encoded_dataset = dataset.map(tokenize_function, batched=True, remove_columns = ['TEXT', 'CATEGORY'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /mnt/sdc/niallt/.cache/csv/default-e82d422e95c8b033/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1/cache-e73aa4be21fbee76.arrow\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a77a516715154109899dab0a8014d424",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lm_datasets  = encoded_dataset.map(preprocess_function, batched = True, batch_size = 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['category_label', 'input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 1000\n",
       "    })\n",
       "    valid: Dataset({\n",
       "        features: ['category_label', 'input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 1000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['category_label', 'input_ids', 'attention_mask', 'labels'],\n",
       "    num_rows: 1000\n",
       "})"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm_datasets['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data_collator = DataCollatorForLanguageModeling(\n",
    "    tokenizer=tokenizer, mlm=True, mlm_probability=0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PeftModel(\n",
       "  (base_model): LoraModel(\n",
       "    (model): TransformerForPreTraining(\n",
       "      (roberta): RobertaModel(\n",
       "        (embeddings): RobertaEmbeddings(\n",
       "          (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
       "          (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "          (token_type_embeddings): Embedding(1, 768)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (encoder): RobertaEncoder(\n",
       "          (layer): ModuleList(\n",
       "            (0-11): 12 x RobertaLayer(\n",
       "              (attention): RobertaAttention(\n",
       "                (self): RobertaSelfAttention(\n",
       "                  (query): Linear(\n",
       "                    in_features=768, out_features=768, bias=True\n",
       "                    (lora_dropout): ModuleDict(\n",
       "                      (default): Dropout(p=0.1, inplace=False)\n",
       "                    )\n",
       "                    (lora_A): ModuleDict(\n",
       "                      (default): Linear(in_features=768, out_features=8, bias=False)\n",
       "                    )\n",
       "                    (lora_B): ModuleDict(\n",
       "                      (default): Linear(in_features=8, out_features=768, bias=False)\n",
       "                    )\n",
       "                    (lora_embedding_A): ParameterDict()\n",
       "                    (lora_embedding_B): ParameterDict()\n",
       "                  )\n",
       "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (value): Linear(\n",
       "                    in_features=768, out_features=768, bias=True\n",
       "                    (lora_dropout): ModuleDict(\n",
       "                      (default): Dropout(p=0.1, inplace=False)\n",
       "                    )\n",
       "                    (lora_A): ModuleDict(\n",
       "                      (default): Linear(in_features=768, out_features=8, bias=False)\n",
       "                    )\n",
       "                    (lora_B): ModuleDict(\n",
       "                      (default): Linear(in_features=8, out_features=768, bias=False)\n",
       "                    )\n",
       "                    (lora_embedding_A): ParameterDict()\n",
       "                    (lora_embedding_B): ParameterDict()\n",
       "                  )\n",
       "                  (dropout): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (output): RobertaSelfOutput(\n",
       "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                  (dropout): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (intermediate): RobertaIntermediate(\n",
       "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "                (intermediate_act_fn): GELUActivation()\n",
       "              )\n",
       "              (output): RobertaOutput(\n",
       "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (lm_head): RobertaLMHead(\n",
       "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (decoder): Linear(in_features=768, out_features=50265, bias=True)\n",
       "      )\n",
       "      (seq_classifier): MeanSequenceClassifier(\n",
       "        (classifier): Linear(in_features=768, out_features=12, bias=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'category_label': tensor([1]), 'input_ids': tensor([[    0,   466,    35,  2518,  4751,   740,    90,   614,  8935,   885,\n",
      "            73,   139,   740,   314,   131,   740,    90,   614,  8935,   885,\n",
      "            73,   139, 50264,   235, 50264,   849,   740,    90, 18228,  1219,\n",
      "            35,  2540, 10516,  9526,   795,  2985,     6, 35713, 50264,  1730,\n",
      "            13,  8795, 13874,  9726,    35,   579,    73,   642,  1136,  1131,\n",
      "          1881, 43767,  2908,    76,   793,   313,   579,    73,   642,  1136,\n",
      "            31,  1510,  1730,  1219,    13,    42,  9027, 50264,  2540, 10516,\n",
      "          9526,   795,  2985,     6, 35713, 50264, 50264,    13,  8795,   117,\n",
      "          8541, 50264,   417, 29758,    13, 40436,  5709,   507,   266,  7335,\n",
      "            35,  2194,   618,  1136,    31,  1510,  1730,    19,  9526, 50264,\n",
      "         28456,     4,  9205,    35, 50264,  2368,  3566, 41402, 18884,  2617,\n",
      "          3156,    58,  4756,    31,     5,  7018,   337, 50264, 18739,     8,\n",
      "         19961,  5571,   149,     5, 50264, 16980,  4899, 50264,    11,   258,\n",
      "             5,   235,     8,   314,  1730,     4,  9240, 20171, 50264, 17929,\n",
      "         20743, 15190, 19747, 50264,    58,  3744,    13,   258,  1730,     4,\n",
      "         50264,    90,   235,  2767, 50264, 17929, 20743, 50264,  9240, 20171,\n",
      "          3114,  2923,    35, 50264,    16,    10, 32581,  7034,   179, 13735,\n",
      "         22259,  3329, 50264,  1445,   809,     9,     5, 43916,  1728,   687,\n",
      "             4,    11,  1285,     6,     5,  7451, 18631,  1496,    16,  2198,\n",
      "         15902,    19, 22259,   149,     5,  5397,     9,     5, 50264,   687,\n",
      "             8, 28510, 44016, 50264, 50264, 50264, 15079,   271,   809,     4,\n",
      "             5, 15079, 50264,   809, 50264,    67, 34988,   352,  5667, 12944,\n",
      "             4,     5, 50264,     9,     5,  7451, 18631, 50264,    16,    67,\n",
      "         50264,    30, 50264,  9013, 27958,   624,  2660,   980,     4,     5,\n",
      "         34988, 15079,   687, 39906,  6329,    19,     5, 31428, 21953,  9013,\n",
      "             4,    11,  1285,     6, 50264, 34988,   144, 37903,     9,     5,\n",
      "         43916,  1728,   687, 33087, 15719,    19,     5, 18383, 12572,     4,\n",
      "            89,    16,    10, 50264,  9148,   149,     5, 50264,   337, 50264,\n",
      "         18739,    88,     5, 41834,  6659, 50264,     5, 15079,   271, 31346,\n",
      "             8,   149,  1533, 43916,  1728,   337, 27958, 50264,   740,    90,\n",
      "           314,  2767,    19,  9240, 20171,     8, 17929, 20743,  3114, 50264,\n",
      "          3156,    35,    89,    16, 50264,  7034,   179, 13735, 22259,  3329,\n",
      "             5,  1445, 43916, 50264,   687,     4,     5, 15079, 50264,   438,\n",
      "          1728,   337,  2660,    16, 50264, 50264,   959,     6,     5,  7451,\n",
      "         18631,  1496,    16, 50264,     4,    89, 50264, 10044,     9,     5,\n",
      "         15079,   261,  1469, 21953,  2660,    19, 34988, 10295, 50264, 26260,\n",
      "             9,     5, 31428, 21953, 50264,     8,  7019, 18900,     9,     5,\n",
      "         47152,  6659,     9,    42, 50264, 11264,     4, 50264,    16,    10,\n",
      "         26956, 22259, 50264,   552,     5,   251, 31799,     9,     5,    78,\n",
      "          1145, 40487, 50264,  9013, 50264,  9148,    88,     5,   326,  2726,\n",
      "         50264, 50264, 50264,  2660,     4,    89,    16,    10, 15970,  2368,\n",
      "          9871, 22259,   149,     5, 47152,  6659,     9,     5, 30972,   740,\n",
      "          4438, 38263,     4, 50264,   352,     6,    89,    16,    10, 29470,\n",
      "           354, 12459, 22259,   149,     5,  7018,   337, 19961,  5571,     4,\n",
      "          8450,    35, 50264, 50264,     9, 50264,  1730,     6,    19,  1498,\n",
      "         10044, 50264,     5, 50264,  7451, 50264,  1496,     4,     2,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0]]), 'labels': tensor([[ -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "          -100,  -100,   740,  -100,  7200,   849,  -100,  -100,  -100,  -100,\n",
      "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,     6,  -100,\n",
      "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "          -100,    35,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "          -100,  -100,  -100,  -100,  -100,  -100,  -100,    35,  -100,  -100,\n",
      "          -100,  -100,  -100,  -100,  -100,     6,  1730,  -100,  -100,  -100,\n",
      "          -100,  9946,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  2767,\n",
      "         28456,  -100,  -100,  -100, 47699,  -100,  -100,  -100,  -100,  -100,\n",
      "          -100,  -100,  -100,  -100,  -100,  -100,  -100,   326,  -100,  -100,\n",
      "          -100,  -100,  -100,  -100, 43860,  -100,  -100,  2917,  -100,  -100,\n",
      "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,     8,  -100,\n",
      "          -100,  3114,  -100,  3156,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "           740,  -100,  -100,  -100,    19,  -100,  -100,     8,  -100,  -100,\n",
      "          -100,  -100,  -100,    89,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "          -100,  -100,     5,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "          -100,  -100,  -100,  -100,     5,  -100,  -100,  -100, 15079,  -100,\n",
      "          -100,  -100,  -100, 26260,     9,     5,  -100,  -100,  -100,  -100,\n",
      "          -100,  -100,   271,  -100,    16,  -100,  -100,  -100,  -100,  -100,\n",
      "          -100,  -100, 10044,  -100,  -100,  -100,  -100,  1496,  -100,  -100,\n",
      "          6336,  -100,  3617,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "          -100,  -100,  -100,  -100,  -100,  -100,  -100, 31428,  -100,  -100,\n",
      "          -100,  -100,  -100,  -100,     5,  -100,  -100,  -100,  -100,  -100,\n",
      "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "          -100,  -100,  -100,  7756,  -100,  -100,  -100,  7018,  -100,   326,\n",
      "          -100,  -100,  -100,  -100,  -100,     9,  -100,  -100,  -100, 31346,\n",
      "          -100,  -100,  -100,  -100,  -100,  -100,  -100,     4,  -100,  -100,\n",
      "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100, 19747,\n",
      "          -100,  -100,  -100,  -100,  4760,  -100,  -100,  -100,  -100,  -100,\n",
      "          -100,  -100,  -100,  1728,  -100,  -100,  -100,  -100, 21103,  -100,\n",
      "          -100,  -100,  -100,  -100, 15902,     4,  -100,  -100,  -100,  -100,\n",
      "          -100,  -100,  -100, 18772,  -100,  -100,    16,  -100,  -100,  -100,\n",
      "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  7019,  -100,\n",
      "          -100,  -100,  -100,  -100,  9013,  -100,  -100,  -100,  -100,  -100,\n",
      "          -100,  -100,  -100,    42, 33087, 11264,  -100,    89,  -100,  -100,\n",
      "          -100,  -100,    67,  -100,  -100,  -100,  -100,  -100,  -100,    78,\n",
      "          -100,  -100,   337,  -100,     6,  -100,  -100,  -100,  -100,  -100,\n",
      "         11174, 40487,   337,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "          -100,  -100,  -100,    94,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "          -100,  -100, 22259,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "          -100,  -100,  2632, 28456,  -100,   258,  -100,  -100,  -100,  -100,\n",
      "          -100,     9,  -100,   235,  -100, 18631,  -100,  -100,  -100,  -100,\n",
      "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "          -100,  -100]])}\n",
      "torch.Size([1, 512])\n"
     ]
    }
   ],
   "source": [
    "for i in lm_datasets['train']:\n",
    "    # print(i)\n",
    "    # print(data_collator([i]))\n",
    "    batch = data_collator([i])\n",
    "    print(batch)\n",
    "    print(batch['input_ids'].shape)\n",
    "    outputs = model(**batch)\n",
    "    \n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TransformerForPreTrainingOutput([('loss',\n",
       "                                  tensor(1.9225, grad_fn=<AddBackward0>)),\n",
       "                                 ('mlm_loss',\n",
       "                                  tensor(1.9225, grad_fn=<NllLossBackward0>)),\n",
       "                                 ('cls_loss',\n",
       "                                  tensor(0., grad_fn=<SumBackward0>)),\n",
       "                                 ('prediction_logits',\n",
       "                                  tensor([[[33.5637, -4.1026, 15.1689,  ...,  2.7973,  4.6324, 11.7745],\n",
       "                                           [ 3.3638, -3.9661, 15.9210,  ...,  0.3801, -1.7152,  3.6887],\n",
       "                                           [-2.6174, -4.3964, 14.8724,  ..., -1.6238, -2.5521,  1.4594],\n",
       "                                           ...,\n",
       "                                           [14.1691, -4.4073, 28.0812,  ..., -0.5447, -3.0653,  9.6223],\n",
       "                                           [14.1691, -4.4073, 28.0812,  ..., -0.5447, -3.0653,  9.6223],\n",
       "                                           [14.1691, -4.4073, 28.0812,  ..., -0.5447, -3.0653,  9.6223]]],\n",
       "                                         grad_fn=<ViewBackward0>)),\n",
       "                                 ('seq_classifier_logits', None),\n",
       "                                 ('hidden_states', None),\n",
       "                                 ('attentions', None),\n",
       "                                 ('seq_embedding',\n",
       "                                  tensor([[ 1.7266e-02,  8.5517e-02,  6.4318e-02,  6.5131e-02,  1.2111e-01,\n",
       "                                           -9.9468e-02, -3.8700e-02,  1.3530e-01,  6.7779e-02,  2.1375e-02,\n",
       "                                           -2.6003e-01, -1.1513e-01,  9.8107e-02, -4.9030e-02,  2.1718e-01,\n",
       "                                           -1.7168e-01,  1.4513e-01, -7.7498e-02, -2.8916e-02, -2.3125e-02,\n",
       "                                           -1.9014e-02,  9.0453e-02,  3.5624e-02,  1.1931e-01, -5.5985e-03,\n",
       "                                           -3.9192e-03,  6.5911e-02, -1.1392e-01, -1.3079e-01,  9.6853e-02,\n",
       "                                           -3.0707e-02,  6.6650e-03, -8.9125e-02, -2.1572e-02, -1.4623e-01,\n",
       "                                           -3.6216e-02,  7.3584e-02,  6.4700e-02,  2.3182e-01,  1.6636e-03,\n",
       "                                           -1.0088e-01, -1.9715e-01, -5.7064e-02, -1.0179e-01, -2.5708e-02,\n",
       "                                            7.0684e-02, -8.8169e-02,  2.3054e-01,  1.2559e-02,  2.8955e-02,\n",
       "                                            6.7181e-03, -3.6360e-02, -6.0215e-02, -4.7056e-02, -1.0036e-01,\n",
       "                                           -3.4869e-02,  1.4975e-01, -1.1456e-01,  1.6250e-01, -1.0723e-01,\n",
       "                                            2.9767e-03,  1.0282e-01, -1.3718e-01,  6.1699e-02, -6.2503e-02,\n",
       "                                           -1.0624e-01,  3.6791e-02, -1.2607e-01,  1.3531e-01,  8.6394e-02,\n",
       "                                            4.6708e-02, -9.4219e-02, -3.8736e-02, -9.2253e-02,  1.1156e-01,\n",
       "                                            1.1287e-01,  9.7907e-03, -3.5653e+00, -3.4259e-02,  2.5323e-01,\n",
       "                                            4.3055e-02,  2.5602e-04,  4.4142e-01, -2.5573e-03,  5.9020e-03,\n",
       "                                           -4.1653e-01,  9.0157e-02, -9.2886e-02,  6.6572e-02,  7.8308e-02,\n",
       "                                           -7.4560e-02,  1.0463e-02, -1.4604e-02,  3.4219e-02,  1.1904e-01,\n",
       "                                            1.1661e-01, -9.9514e-03, -2.5883e-01, -2.9641e-02, -6.8312e-02,\n",
       "                                            2.4277e-01,  3.4425e-02, -6.9479e-02,  3.6597e-02,  4.1426e-02,\n",
       "                                           -8.6620e-03,  1.6892e-02,  8.3337e-02, -7.8379e-03,  4.8184e-02,\n",
       "                                            1.9729e-02,  1.1132e-02,  9.9096e-02,  5.5122e-02,  3.1145e-02,\n",
       "                                           -9.3779e-02,  6.0711e-02, -3.1741e-02,  1.0461e-01, -7.3486e-03,\n",
       "                                            1.8638e-01,  6.7854e-02,  6.7763e-02, -4.3339e-03,  1.4761e-02,\n",
       "                                            8.6685e-02, -1.1868e-01, -6.4092e-03,  5.1424e-02, -6.0994e-02,\n",
       "                                           -6.8372e-02, -2.9251e-01, -7.6624e-02, -1.2123e-01,  7.9636e-02,\n",
       "                                           -3.4399e-02, -7.0261e-02, -8.6503e-02,  1.2252e-01,  1.5615e-01,\n",
       "                                            1.5809e-02, -5.8420e-02, -3.0500e-02, -6.0861e-02,  1.0512e-01,\n",
       "                                           -2.6687e-02,  3.2597e-02, -1.3157e-02,  4.6404e-02,  5.9193e-02,\n",
       "                                            9.2604e-02, -1.4224e-01, -8.7049e-02, -1.1846e-02, -2.7774e-02,\n",
       "                                            2.1144e-01,  5.5955e-02,  1.4345e-01,  5.2501e-03,  2.9268e-01,\n",
       "                                            1.8979e-01,  2.6190e-02, -1.6949e-03,  7.5979e-05, -9.0137e-02,\n",
       "                                            1.5461e-02,  7.6022e-03,  5.5354e-02,  3.0303e-02,  7.7363e-02,\n",
       "                                            4.8655e-03,  6.1459e-02,  7.2580e-02,  4.0953e-02,  3.6230e-02,\n",
       "                                           -3.2244e-02,  1.5180e-01,  9.0804e-02,  8.8233e-03, -3.6807e-02,\n",
       "                                            2.0633e-02,  1.6989e-03, -4.3859e-03, -9.9492e-02,  3.8806e-02,\n",
       "                                            1.1576e-01,  3.5801e-02,  7.8058e-02, -9.7795e-02,  1.5506e-02,\n",
       "                                            9.6672e-02,  9.7436e-02, -4.0621e-02,  7.4598e-02,  1.0378e-01,\n",
       "                                           -6.1163e-02,  8.1632e-02,  1.1947e-02,  1.8189e-01, -4.2656e-02,\n",
       "                                           -9.4375e-02,  4.3393e-02,  1.7168e-01, -8.1986e-02,  2.0278e-01,\n",
       "                                           -2.6701e-02, -2.1547e-01,  8.9215e-02,  6.7317e-02, -2.2256e-01,\n",
       "                                            2.6893e-02,  1.5294e-01,  4.3111e-03,  1.0111e-01,  1.1962e-02,\n",
       "                                            1.3777e-01,  1.7217e-02, -5.2110e-01, -1.5016e-01, -1.6172e-01,\n",
       "                                            1.2238e-01,  7.8987e-02,  2.3327e-02, -6.5708e-02,  1.3953e-01,\n",
       "                                            6.7433e-02, -1.2940e-02,  1.8499e-02,  6.1261e-02,  1.7005e-01,\n",
       "                                            1.1353e-02, -9.7127e-02, -1.2604e-01,  1.4072e-01,  1.9614e-02,\n",
       "                                           -3.0075e-01, -1.0565e-02, -1.7815e-02,  1.0039e-01,  6.8843e-02,\n",
       "                                           -6.6059e-01,  7.1232e-02, -1.4591e-02,  1.0345e-01,  2.9921e-02,\n",
       "                                           -6.8437e-03, -1.8797e-02, -4.6630e-02,  3.8398e-02,  3.5669e-02,\n",
       "                                           -2.8971e-02, -1.8400e-01, -4.9275e-02, -2.4087e-02,  1.8662e-01,\n",
       "                                           -9.0957e-02,  3.1777e-02, -6.0130e-02, -1.3262e-01, -1.5594e-01,\n",
       "                                            5.3460e-02, -6.1650e-02,  1.2299e-01,  8.3797e-02, -4.5081e-02,\n",
       "                                            1.2928e-01, -2.9507e-02, -1.3416e-01,  1.0277e-01,  3.2266e-02,\n",
       "                                            1.5374e-02,  3.7410e-02, -9.8435e-03, -4.8721e-03,  7.8774e-02,\n",
       "                                            6.3763e-02, -9.3909e-02,  1.9078e-02, -3.4394e-02,  2.1144e-03,\n",
       "                                           -3.0186e-02, -5.6439e-02,  1.9267e-02, -7.8109e-02, -1.5187e-03,\n",
       "                                           -1.0163e-01, -2.6991e-01, -9.9741e-02, -5.4435e-02, -3.3713e-03,\n",
       "                                           -5.2966e-02,  1.0161e-01,  2.4704e-02,  2.5948e-03, -2.1349e-03,\n",
       "                                           -3.0868e-02, -1.0801e-02,  1.8532e-02,  5.7184e-02, -8.2913e-02,\n",
       "                                            2.5815e-01,  3.8133e-02, -1.9438e-02, -7.8843e-03, -7.9312e-02,\n",
       "                                            9.4620e-02,  3.6832e-03,  4.9548e-02,  9.3949e-02,  1.4893e-01,\n",
       "                                           -5.9632e-04,  1.5597e-02, -8.0524e-02,  1.3735e-01, -1.3390e-02,\n",
       "                                            2.0059e-02,  2.5772e-02, -2.1421e-03,  6.2148e-02,  1.7616e-02,\n",
       "                                            5.9701e-02,  6.9593e-02,  2.7276e-02,  2.0897e-02, -8.0959e-02,\n",
       "                                            1.3794e-01, -1.9797e-01,  9.9382e-02,  4.9377e-02,  9.6063e-02,\n",
       "                                            1.4819e+00,  7.5265e-01,  1.0788e-01,  1.1795e-01, -1.5718e-02,\n",
       "                                            3.9956e-02, -1.2360e-01,  6.0417e-02,  1.2489e-01,  1.5927e-01,\n",
       "                                           -7.4091e-02, -1.2657e-01,  8.0239e-03,  3.2014e-03,  3.3304e-02,\n",
       "                                            2.3456e-02,  1.1358e-01,  1.9199e-02,  1.2852e-01,  1.3175e-01,\n",
       "                                            1.2789e-01,  1.2628e-02,  2.6752e-02, -4.2489e-03,  9.4722e-02,\n",
       "                                            1.8207e-01, -1.7385e-01,  4.0547e-02, -5.3398e-02, -2.8927e-01,\n",
       "                                           -1.1336e-02,  1.6236e-01, -7.3303e-02, -1.1458e-01, -9.8086e-02,\n",
       "                                           -2.1266e-02,  1.3462e-02,  7.7087e-02,  3.0343e-02,  7.5871e-02,\n",
       "                                            1.0129e-01,  2.1804e-02,  2.4256e-02, -6.2643e-02, -1.4650e-01,\n",
       "                                           -3.6808e-02, -9.8069e-02, -8.0260e-02, -4.5634e-02, -2.7189e-02,\n",
       "                                            1.3613e-02,  5.5009e-02, -1.3284e-01,  2.0462e-02,  1.3726e-01,\n",
       "                                           -3.9888e-02, -8.5799e-02, -4.2376e-03,  1.9493e-01,  6.9778e-02,\n",
       "                                            5.2572e-03,  9.1921e-02, -1.0059e-01,  3.7749e-02,  4.2336e-02,\n",
       "                                           -5.2888e-02,  1.6973e-01, -4.4813e-01,  1.2619e-03, -7.0054e-02,\n",
       "                                            1.1671e-02,  9.8197e-02,  4.7503e-02,  1.3075e-01,  7.1392e-02,\n",
       "                                            4.3595e-02, -9.5442e-02, -2.3564e-02,  1.1497e-02,  1.4438e-01,\n",
       "                                            7.3233e-03, -6.2362e-02, -2.7428e-02,  5.1955e-03,  7.1045e-02,\n",
       "                                            2.2854e-04,  1.0419e-01,  7.0438e-02,  1.4277e-01, -6.2566e-02,\n",
       "                                           -5.2993e-02,  4.8706e-02,  1.4605e-01, -3.3143e-02, -9.5426e-02,\n",
       "                                           -2.2517e-03,  1.5178e-01, -5.6823e-02,  1.7038e-01,  6.4525e-03,\n",
       "                                            6.9231e-02, -3.5785e-02, -7.6650e-02,  5.4909e-03, -9.4753e-02,\n",
       "                                           -2.4705e-02,  8.2065e-02,  4.0720e-02, -6.0330e-02, -9.6363e-02,\n",
       "                                           -7.9049e-03,  5.4037e-02,  7.6307e-02,  3.6739e-02, -8.6635e-02,\n",
       "                                            1.3606e-01,  3.6703e-02,  2.9573e-02,  6.4999e-02,  7.3343e-02,\n",
       "                                            3.9887e-02, -6.1279e-02, -1.2469e-01, -7.4484e-01,  1.3201e-01,\n",
       "                                            4.3020e-02,  1.0731e-01,  1.0013e-01, -1.2126e-01,  1.7514e-02,\n",
       "                                           -1.2114e-01,  5.2656e-02, -3.3201e-02, -5.6165e-02, -1.7119e-02,\n",
       "                                            2.8733e-02, -6.9401e-02, -4.6407e-02,  4.7401e-02,  3.0197e-02,\n",
       "                                            4.8114e-02, -8.5318e-02, -2.7034e-02, -1.3224e-01,  7.4748e-02,\n",
       "                                           -6.0700e-02, -6.0683e-02, -1.3893e-01,  4.4459e-03, -2.1639e-02,\n",
       "                                            6.4815e-02,  3.5281e-02,  3.7363e-03,  1.6196e-04, -1.9169e-02,\n",
       "                                           -8.9182e-03,  1.0206e-01, -1.4736e-02,  8.3030e-02, -1.1527e-02,\n",
       "                                           -8.9407e-02,  3.2064e-02,  1.8436e-02,  6.4015e-02,  1.5730e-01,\n",
       "                                            3.3297e-02, -1.2172e+00,  5.0861e-02, -3.6336e-01,  6.8019e-02,\n",
       "                                            4.0734e-02, -2.0370e-02, -6.7254e-02,  8.9241e-02,  2.7440e-02,\n",
       "                                            1.7222e-02, -1.3665e-02,  1.2911e-02, -1.2811e-01, -5.4585e-02,\n",
       "                                            8.5888e-02,  5.8072e-02, -1.3338e-02, -6.0510e-02, -3.1923e-03,\n",
       "                                           -3.1801e-02,  7.4131e-02, -9.0137e-02,  1.2698e-01,  2.1048e-01,\n",
       "                                            5.5901e-02,  8.9807e-02, -2.9768e-02,  6.2742e-02, -3.4649e-02,\n",
       "                                           -4.1087e-02, -1.0856e-01, -2.7207e-02, -4.1084e-03, -1.1781e-01,\n",
       "                                            2.0144e-01, -8.8838e-03,  2.2009e-01,  3.8341e-02, -1.7242e-01,\n",
       "                                            8.8047e-02, -1.8050e-02,  3.2183e-02,  1.5081e-01,  1.2540e-01,\n",
       "                                           -4.9072e-02, -1.1667e-01,  1.0104e-01, -1.1162e-01,  1.3550e-02,\n",
       "                                           -9.3388e-02,  8.1838e-02,  3.5368e-02,  3.8091e-02, -1.2095e-01,\n",
       "                                           -6.0728e-02,  3.6628e+00,  8.6674e-02,  5.6130e-02, -1.5004e-01,\n",
       "                                            4.9499e-02, -4.3584e-02,  1.5965e-02, -3.2037e-02,  6.2419e-03,\n",
       "                                            4.1906e-02,  1.9092e-03,  1.8559e-02,  7.7810e-02,  1.3760e-01,\n",
       "                                           -1.0017e-01,  1.5875e-02, -1.2402e-01,  5.9065e-03,  1.5743e-01,\n",
       "                                           -1.1872e-01,  4.4908e-02, -1.0802e-01,  6.9515e-02,  1.6777e-01,\n",
       "                                           -8.4220e-03,  3.8239e-02,  1.8768e-01,  1.0194e-01,  4.9894e-02,\n",
       "                                            2.7197e-01,  1.1068e-01,  2.6732e-02, -3.6792e-02,  8.5890e-02,\n",
       "                                           -2.7221e-02,  6.7426e-02, -5.3468e-02,  9.4421e+00,  4.5341e-02,\n",
       "                                            1.1601e-02,  7.2440e-03,  4.8962e-02, -7.1333e-02, -9.1898e-02,\n",
       "                                           -2.4813e-02,  1.9132e-02,  5.1467e-02, -5.3756e-03, -7.1489e-03,\n",
       "                                            1.6532e-02, -1.5877e-01,  2.7176e-03, -9.1016e-02,  1.0517e-01,\n",
       "                                           -1.4927e-01,  1.0465e-01, -1.0920e-02,  8.0124e-02,  1.6934e-02,\n",
       "                                            5.7232e-02,  4.3310e-01, -8.0591e-03,  4.6938e-03,  1.4334e-01,\n",
       "                                            3.7055e-02, -4.0462e-02,  4.1141e-02, -6.9879e-02,  9.6260e-02,\n",
       "                                            4.2629e-02,  6.8256e-02, -3.8799e-02, -3.4005e-02, -2.1514e-01,\n",
       "                                            1.0078e-01, -7.7971e-03,  2.1227e-02,  1.0448e-01,  7.1269e-03,\n",
       "                                            2.9908e-03, -3.3738e-02,  2.1042e-02, -2.7850e-02,  5.5216e-02,\n",
       "                                            4.8012e-02, -4.9050e-02, -7.7293e-02,  3.8146e-02,  6.6802e-02,\n",
       "                                            7.4053e-02, -3.5420e-02,  4.2617e-02,  1.2513e-02,  6.4002e-02,\n",
       "                                            1.0773e-01,  4.8717e-02,  1.1337e-01,  6.3845e-02,  3.1538e-02,\n",
       "                                           -2.6417e-02, -5.1917e-02, -1.7562e-01, -6.5052e-02,  1.3538e-01,\n",
       "                                           -1.1456e-01,  5.8020e-02, -1.8797e-01, -9.6136e-03, -5.6641e-02,\n",
       "                                           -1.1830e-01,  5.0244e-02, -5.8122e-02,  1.1426e-01,  4.4088e-01,\n",
       "                                           -7.9549e-03, -6.4142e-02,  1.9419e-02,  1.0295e-01,  2.8743e-02,\n",
       "                                            1.1882e-01,  6.1711e-03, -2.3295e-01,  2.0817e-01,  1.9706e-02,\n",
       "                                           -3.0177e-02, -6.5882e-02, -9.1600e-02, -1.6706e-02,  1.5271e-01,\n",
       "                                            9.3775e-02,  9.7523e-03, -2.2766e-02, -5.8290e-02,  4.1258e-04,\n",
       "                                           -4.0731e-02,  7.7215e-02, -6.8748e-02, -3.9282e-02,  3.3022e-02,\n",
       "                                           -6.7798e-02, -2.7418e-02, -5.4739e-03,  8.3371e-02, -3.6579e-02,\n",
       "                                           -7.0023e-02,  3.2409e-02,  3.1660e-02, -2.6033e-02, -7.3459e-02,\n",
       "                                            6.0957e-02,  7.7477e-03,  2.5586e-02, -3.3289e-02,  7.8373e-02,\n",
       "                                            6.0597e-03,  7.1454e-02,  1.7362e-02, -2.9845e-02,  1.5808e-02,\n",
       "                                           -8.1755e-02,  2.0938e-02, -7.5551e-03,  9.8583e-02, -1.8356e-03,\n",
       "                                           -6.5102e-02, -2.5823e-01,  5.8274e-02,  1.1340e-01,  5.1951e-02,\n",
       "                                            1.3254e-01, -4.0564e-02,  9.3891e-02, -2.0238e-02, -2.6265e-02,\n",
       "                                            8.0977e-02, -1.7639e-01,  1.2724e-01,  4.0399e-02,  1.1368e-01,\n",
       "                                           -1.7615e-02, -3.3353e-01, -1.9243e-02, -8.0238e-02, -5.6311e-02,\n",
       "                                            1.6487e-01, -1.3684e-01,  1.9750e-02, -6.4223e-02,  7.2292e-02,\n",
       "                                            1.7637e-01, -5.7041e-02, -4.3732e-02,  2.3583e-03,  5.6259e-03,\n",
       "                                            1.0239e-01, -5.7265e-02, -5.2620e-02, -1.2973e-02,  1.2422e-01,\n",
       "                                           -1.0723e-01, -7.7191e-02, -1.9027e-01, -2.4839e-02,  6.9801e-02,\n",
       "                                           -4.4420e-02,  6.2926e-02, -4.0621e-02, -8.9339e-02,  8.2264e-02,\n",
       "                                           -3.0278e-02, -2.5263e-02, -2.0355e-01,  2.0259e-02, -1.0588e-01,\n",
       "                                           -1.8494e-01,  1.1225e-01, -3.3393e-02]], grad_fn=<DivBackward0>))])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 768])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs.seq_embedding.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PeftModel(\n",
       "  (base_model): LoraModel(\n",
       "    (model): TransformerForPreTraining(\n",
       "      (roberta): RobertaModel(\n",
       "        (embeddings): RobertaEmbeddings(\n",
       "          (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
       "          (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "          (token_type_embeddings): Embedding(1, 768)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (encoder): RobertaEncoder(\n",
       "          (layer): ModuleList(\n",
       "            (0-11): 12 x RobertaLayer(\n",
       "              (attention): RobertaAttention(\n",
       "                (self): RobertaSelfAttention(\n",
       "                  (query): Linear(\n",
       "                    in_features=768, out_features=768, bias=True\n",
       "                    (lora_dropout): ModuleDict(\n",
       "                      (default): Dropout(p=0.1, inplace=False)\n",
       "                    )\n",
       "                    (lora_A): ModuleDict(\n",
       "                      (default): Linear(in_features=768, out_features=8, bias=False)\n",
       "                    )\n",
       "                    (lora_B): ModuleDict(\n",
       "                      (default): Linear(in_features=8, out_features=768, bias=False)\n",
       "                    )\n",
       "                    (lora_embedding_A): ParameterDict()\n",
       "                    (lora_embedding_B): ParameterDict()\n",
       "                  )\n",
       "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (value): Linear(\n",
       "                    in_features=768, out_features=768, bias=True\n",
       "                    (lora_dropout): ModuleDict(\n",
       "                      (default): Dropout(p=0.1, inplace=False)\n",
       "                    )\n",
       "                    (lora_A): ModuleDict(\n",
       "                      (default): Linear(in_features=768, out_features=8, bias=False)\n",
       "                    )\n",
       "                    (lora_B): ModuleDict(\n",
       "                      (default): Linear(in_features=8, out_features=768, bias=False)\n",
       "                    )\n",
       "                    (lora_embedding_A): ParameterDict()\n",
       "                    (lora_embedding_B): ParameterDict()\n",
       "                  )\n",
       "                  (dropout): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (output): RobertaSelfOutput(\n",
       "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                  (dropout): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (intermediate): RobertaIntermediate(\n",
       "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "                (intermediate_act_fn): GELUActivation()\n",
       "              )\n",
       "              (output): RobertaOutput(\n",
       "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (lm_head): RobertaLMHead(\n",
       "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (decoder): Linear(in_features=768, out_features=50265, bias=True)\n",
       "      )\n",
       "      (seq_classifier): MeanSequenceClassifier(\n",
       "        (classifier): Linear(in_features=768, out_features=12, bias=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# look at freezing then unfreezing certain layers\n",
    "\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name is: \n",
      "Name is: embeddings\n",
      "Name is: embeddings.word_embeddings\n",
      "Name is: embeddings.position_embeddings\n",
      "Name is: embeddings.token_type_embeddings\n",
      "Name is: embeddings.LayerNorm\n",
      "Name is: embeddings.dropout\n",
      "Name is: encoder\n",
      "Name is: encoder.layer\n",
      "Name is: encoder.layer.0\n",
      "Name is: encoder.layer.0.attention\n",
      "Name is: encoder.layer.0.attention.self\n",
      "Name is: encoder.layer.0.attention.self.query\n",
      "Name is: encoder.layer.0.attention.self.key\n",
      "Name is: encoder.layer.0.attention.self.value\n",
      "Name is: encoder.layer.0.attention.self.dropout\n",
      "Name is: encoder.layer.0.attention.output\n",
      "Name is: encoder.layer.0.attention.output.dense\n",
      "Name is: encoder.layer.0.attention.output.LayerNorm\n",
      "Name is: encoder.layer.0.attention.output.dropout\n",
      "Name is: encoder.layer.0.intermediate\n",
      "Name is: encoder.layer.0.intermediate.dense\n",
      "Name is: encoder.layer.0.intermediate.intermediate_act_fn\n",
      "Name is: encoder.layer.0.output\n",
      "Name is: encoder.layer.0.output.dense\n",
      "Name is: encoder.layer.0.output.LayerNorm\n",
      "Name is: encoder.layer.0.output.dropout\n",
      "Name is: encoder.layer.1\n",
      "Name is: encoder.layer.1.attention\n",
      "Name is: encoder.layer.1.attention.self\n",
      "Name is: encoder.layer.1.attention.self.query\n",
      "Name is: encoder.layer.1.attention.self.key\n",
      "Name is: encoder.layer.1.attention.self.value\n",
      "Name is: encoder.layer.1.attention.self.dropout\n",
      "Name is: encoder.layer.1.attention.output\n",
      "Name is: encoder.layer.1.attention.output.dense\n",
      "Name is: encoder.layer.1.attention.output.LayerNorm\n",
      "Name is: encoder.layer.1.attention.output.dropout\n",
      "Name is: encoder.layer.1.intermediate\n",
      "Name is: encoder.layer.1.intermediate.dense\n",
      "Name is: encoder.layer.1.output\n",
      "Name is: encoder.layer.1.output.dense\n",
      "Name is: encoder.layer.1.output.LayerNorm\n",
      "Name is: encoder.layer.1.output.dropout\n",
      "Name is: encoder.layer.2\n",
      "Name is: encoder.layer.2.attention\n",
      "Name is: encoder.layer.2.attention.self\n",
      "Name is: encoder.layer.2.attention.self.query\n",
      "Name is: encoder.layer.2.attention.self.key\n",
      "Name is: encoder.layer.2.attention.self.value\n",
      "Name is: encoder.layer.2.attention.self.dropout\n",
      "Name is: encoder.layer.2.attention.output\n",
      "Name is: encoder.layer.2.attention.output.dense\n",
      "Name is: encoder.layer.2.attention.output.LayerNorm\n",
      "Name is: encoder.layer.2.attention.output.dropout\n",
      "Name is: encoder.layer.2.intermediate\n",
      "Name is: encoder.layer.2.intermediate.dense\n",
      "Name is: encoder.layer.2.output\n",
      "Name is: encoder.layer.2.output.dense\n",
      "Name is: encoder.layer.2.output.LayerNorm\n",
      "Name is: encoder.layer.2.output.dropout\n",
      "Name is: encoder.layer.3\n",
      "Name is: encoder.layer.3.attention\n",
      "Name is: encoder.layer.3.attention.self\n",
      "Name is: encoder.layer.3.attention.self.query\n",
      "Name is: encoder.layer.3.attention.self.key\n",
      "Name is: encoder.layer.3.attention.self.value\n",
      "Name is: encoder.layer.3.attention.self.dropout\n",
      "Name is: encoder.layer.3.attention.output\n",
      "Name is: encoder.layer.3.attention.output.dense\n",
      "Name is: encoder.layer.3.attention.output.LayerNorm\n",
      "Name is: encoder.layer.3.attention.output.dropout\n",
      "Name is: encoder.layer.3.intermediate\n",
      "Name is: encoder.layer.3.intermediate.dense\n",
      "Name is: encoder.layer.3.output\n",
      "Name is: encoder.layer.3.output.dense\n",
      "Name is: encoder.layer.3.output.LayerNorm\n",
      "Name is: encoder.layer.3.output.dropout\n",
      "Name is: encoder.layer.4\n",
      "Name is: encoder.layer.4.attention\n",
      "Name is: encoder.layer.4.attention.self\n",
      "Name is: encoder.layer.4.attention.self.query\n",
      "Name is: encoder.layer.4.attention.self.key\n",
      "Name is: encoder.layer.4.attention.self.value\n",
      "Name is: encoder.layer.4.attention.self.dropout\n",
      "Name is: encoder.layer.4.attention.output\n",
      "Name is: encoder.layer.4.attention.output.dense\n",
      "Name is: encoder.layer.4.attention.output.LayerNorm\n",
      "Name is: encoder.layer.4.attention.output.dropout\n",
      "Name is: encoder.layer.4.intermediate\n",
      "Name is: encoder.layer.4.intermediate.dense\n",
      "Name is: encoder.layer.4.output\n",
      "Name is: encoder.layer.4.output.dense\n",
      "Name is: encoder.layer.4.output.LayerNorm\n",
      "Name is: encoder.layer.4.output.dropout\n",
      "Name is: encoder.layer.5\n",
      "Name is: encoder.layer.5.attention\n",
      "Name is: encoder.layer.5.attention.self\n",
      "Name is: encoder.layer.5.attention.self.query\n",
      "Name is: encoder.layer.5.attention.self.key\n",
      "Name is: encoder.layer.5.attention.self.value\n",
      "Name is: encoder.layer.5.attention.self.dropout\n",
      "Name is: encoder.layer.5.attention.output\n",
      "Name is: encoder.layer.5.attention.output.dense\n",
      "Name is: encoder.layer.5.attention.output.LayerNorm\n",
      "Name is: encoder.layer.5.attention.output.dropout\n",
      "Name is: encoder.layer.5.intermediate\n",
      "Name is: encoder.layer.5.intermediate.dense\n",
      "Name is: encoder.layer.5.output\n",
      "Name is: encoder.layer.5.output.dense\n",
      "Name is: encoder.layer.5.output.LayerNorm\n",
      "Name is: encoder.layer.5.output.dropout\n",
      "Name is: encoder.layer.6\n",
      "Name is: encoder.layer.6.attention\n",
      "Name is: encoder.layer.6.attention.self\n",
      "Name is: encoder.layer.6.attention.self.query\n",
      "Name is: encoder.layer.6.attention.self.key\n",
      "Name is: encoder.layer.6.attention.self.value\n",
      "Name is: encoder.layer.6.attention.self.dropout\n",
      "Name is: encoder.layer.6.attention.output\n",
      "Name is: encoder.layer.6.attention.output.dense\n",
      "Name is: encoder.layer.6.attention.output.LayerNorm\n",
      "Name is: encoder.layer.6.attention.output.dropout\n",
      "Name is: encoder.layer.6.intermediate\n",
      "Name is: encoder.layer.6.intermediate.dense\n",
      "Name is: encoder.layer.6.output\n",
      "Name is: encoder.layer.6.output.dense\n",
      "Name is: encoder.layer.6.output.LayerNorm\n",
      "Name is: encoder.layer.6.output.dropout\n",
      "Name is: encoder.layer.7\n",
      "Name is: encoder.layer.7.attention\n",
      "Name is: encoder.layer.7.attention.self\n",
      "Name is: encoder.layer.7.attention.self.query\n",
      "Name is: encoder.layer.7.attention.self.key\n",
      "Name is: encoder.layer.7.attention.self.value\n",
      "Name is: encoder.layer.7.attention.self.dropout\n",
      "Name is: encoder.layer.7.attention.output\n",
      "Name is: encoder.layer.7.attention.output.dense\n",
      "Name is: encoder.layer.7.attention.output.LayerNorm\n",
      "Name is: encoder.layer.7.attention.output.dropout\n",
      "Name is: encoder.layer.7.intermediate\n",
      "Name is: encoder.layer.7.intermediate.dense\n",
      "Name is: encoder.layer.7.output\n",
      "Name is: encoder.layer.7.output.dense\n",
      "Name is: encoder.layer.7.output.LayerNorm\n",
      "Name is: encoder.layer.7.output.dropout\n",
      "Name is: encoder.layer.8\n",
      "Name is: encoder.layer.8.attention\n",
      "Name is: encoder.layer.8.attention.self\n",
      "Name is: encoder.layer.8.attention.self.query\n",
      "Name is: encoder.layer.8.attention.self.key\n",
      "Name is: encoder.layer.8.attention.self.value\n",
      "Name is: encoder.layer.8.attention.self.dropout\n",
      "Name is: encoder.layer.8.attention.output\n",
      "Name is: encoder.layer.8.attention.output.dense\n",
      "Name is: encoder.layer.8.attention.output.LayerNorm\n",
      "Name is: encoder.layer.8.attention.output.dropout\n",
      "Name is: encoder.layer.8.intermediate\n",
      "Name is: encoder.layer.8.intermediate.dense\n",
      "Name is: encoder.layer.8.output\n",
      "Name is: encoder.layer.8.output.dense\n",
      "Name is: encoder.layer.8.output.LayerNorm\n",
      "Name is: encoder.layer.8.output.dropout\n",
      "Name is: encoder.layer.9\n",
      "Name is: encoder.layer.9.attention\n",
      "Name is: encoder.layer.9.attention.self\n",
      "Name is: encoder.layer.9.attention.self.query\n",
      "Name is: encoder.layer.9.attention.self.key\n",
      "Name is: encoder.layer.9.attention.self.value\n",
      "Name is: encoder.layer.9.attention.self.dropout\n",
      "Name is: encoder.layer.9.attention.output\n",
      "Name is: encoder.layer.9.attention.output.dense\n",
      "Name is: encoder.layer.9.attention.output.LayerNorm\n",
      "Name is: encoder.layer.9.attention.output.dropout\n",
      "Name is: encoder.layer.9.intermediate\n",
      "Name is: encoder.layer.9.intermediate.dense\n",
      "Name is: encoder.layer.9.output\n",
      "Name is: encoder.layer.9.output.dense\n",
      "Name is: encoder.layer.9.output.LayerNorm\n",
      "Name is: encoder.layer.9.output.dropout\n",
      "Name is: encoder.layer.10\n",
      "Name is: encoder.layer.10.attention\n",
      "Name is: encoder.layer.10.attention.self\n",
      "Name is: encoder.layer.10.attention.self.query\n",
      "Name is: encoder.layer.10.attention.self.key\n",
      "Name is: encoder.layer.10.attention.self.value\n",
      "Name is: encoder.layer.10.attention.self.dropout\n",
      "Name is: encoder.layer.10.attention.output\n",
      "Name is: encoder.layer.10.attention.output.dense\n",
      "Name is: encoder.layer.10.attention.output.LayerNorm\n",
      "Name is: encoder.layer.10.attention.output.dropout\n",
      "Name is: encoder.layer.10.intermediate\n",
      "Name is: encoder.layer.10.intermediate.dense\n",
      "Name is: encoder.layer.10.output\n",
      "Name is: encoder.layer.10.output.dense\n",
      "Name is: encoder.layer.10.output.LayerNorm\n",
      "Name is: encoder.layer.10.output.dropout\n",
      "Name is: encoder.layer.11\n",
      "Name is: encoder.layer.11.attention\n",
      "Name is: encoder.layer.11.attention.self\n",
      "Name is: encoder.layer.11.attention.self.query\n",
      "Name is: encoder.layer.11.attention.self.key\n",
      "Name is: encoder.layer.11.attention.self.value\n",
      "Name is: encoder.layer.11.attention.self.dropout\n",
      "Name is: encoder.layer.11.attention.output\n",
      "Name is: encoder.layer.11.attention.output.dense\n",
      "Name is: encoder.layer.11.attention.output.LayerNorm\n",
      "Name is: encoder.layer.11.attention.output.dropout\n",
      "Name is: encoder.layer.11.intermediate\n",
      "Name is: encoder.layer.11.intermediate.dense\n",
      "Name is: encoder.layer.11.output\n",
      "Name is: encoder.layer.11.output.dense\n",
      "Name is: encoder.layer.11.output.LayerNorm\n",
      "Name is: encoder.layer.11.output.dropout\n"
     ]
    }
   ],
   "source": [
    "for name, param in model.base_model.named_modules():\n",
    "    \n",
    "    print(f\"Name is: {name}\")\n",
    "    # for name, layer in model.base_model.encoder.layer[:13].named_modules():\n",
    "    #     print(f\"layer is: {name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RobertaConfig {\n",
       "  \"_name_or_path\": \"roberta-base\",\n",
       "  \"architectures\": [\n",
       "    \"RobertaForMaskedLM\"\n",
       "  ],\n",
       "  \"attention_probs_dropout_prob\": 0.1,\n",
       "  \"bos_token_id\": 0,\n",
       "  \"classifier_dropout\": null,\n",
       "  \"eos_token_id\": 2,\n",
       "  \"hidden_act\": \"gelu\",\n",
       "  \"hidden_dropout_prob\": 0.1,\n",
       "  \"hidden_size\": 768,\n",
       "  \"initializer_range\": 0.02,\n",
       "  \"intermediate_size\": 3072,\n",
       "  \"layer_norm_eps\": 1e-05,\n",
       "  \"max_position_embeddings\": 514,\n",
       "  \"model_type\": \"roberta\",\n",
       "  \"num_attention_heads\": 12,\n",
       "  \"num_hidden_layers\": 12,\n",
       "  \"pad_token_id\": 1,\n",
       "  \"position_embedding_type\": \"absolute\",\n",
       "  \"transformers_version\": \"4.21.3\",\n",
       "  \"type_vocab_size\": 1,\n",
       "  \"use_cache\": true,\n",
       "  \"vocab_size\": 50265\n",
       "}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.config"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### test training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found safetensors installation, but --save_safetensors=False. Safetensors should be a preferred weights saving format due to security and performance reasons. If your model cannot be saved by safetensors please feel free to open an issue at https://github.com/huggingface/safetensors!\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "/mnt/sdc/niallt/venvs/39nlp/lib/python3.9/site-packages/accelerate/utils/imports.py:197: UserWarning: Intel Extension for PyTorch 1.12 needs to work with PyTorch 1.12.*, but PyTorch 2.0.1 is found. Please switch to the matching version and run again.\n",
      "  warnings.warn(\n",
      "max_steps is given, it will override any value given in num_train_epochs\n",
      "The following columns in the training set don't have a corresponding argument in `PeftModel.forward` and have been ignored: attention_mask, input_ids, labels, category_label. If attention_mask, input_ids, labels, category_label are not expected by `PeftModel.forward`,  you can safely ignore this message.\n",
      "/mnt/sdc/niallt/venvs/39nlp/lib/python3.9/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "Invalid key: 858 is out of bounds for size 0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 42\u001b[0m\n\u001b[1;32m     30\u001b[0m trainer \u001b[39m=\u001b[39m CustomHFTrainer(\n\u001b[1;32m     31\u001b[0m     model\u001b[39m=\u001b[39mmodel,\n\u001b[1;32m     32\u001b[0m     tokenizer \u001b[39m=\u001b[39m tokenizer,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[39m# preprocess_logits_for_metrics = preprocess_logits_for_metrics\u001b[39;00m\n\u001b[1;32m     40\u001b[0m )\n\u001b[1;32m     41\u001b[0m \u001b[39m# run trainer\u001b[39;00m\n\u001b[0;32m---> 42\u001b[0m trainer\u001b[39m.\u001b[39;49mtrain()\n",
      "File \u001b[0;32m/mnt/sdc/niallt/venvs/39nlp/lib/python3.9/site-packages/transformers/trainer.py:1648\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1643\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel_wrapped \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\n\u001b[1;32m   1645\u001b[0m inner_training_loop \u001b[39m=\u001b[39m find_executable_batch_size(\n\u001b[1;32m   1646\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_inner_training_loop, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_train_batch_size, args\u001b[39m.\u001b[39mauto_find_batch_size\n\u001b[1;32m   1647\u001b[0m )\n\u001b[0;32m-> 1648\u001b[0m \u001b[39mreturn\u001b[39;00m inner_training_loop(\n\u001b[1;32m   1649\u001b[0m     args\u001b[39m=\u001b[39;49margs,\n\u001b[1;32m   1650\u001b[0m     resume_from_checkpoint\u001b[39m=\u001b[39;49mresume_from_checkpoint,\n\u001b[1;32m   1651\u001b[0m     trial\u001b[39m=\u001b[39;49mtrial,\n\u001b[1;32m   1652\u001b[0m     ignore_keys_for_eval\u001b[39m=\u001b[39;49mignore_keys_for_eval,\n\u001b[1;32m   1653\u001b[0m )\n",
      "File \u001b[0;32m~/EHR_Embedding_Spaces/Language_Modelling/transformers/models/utils/custom_hf_trainer.py:600\u001b[0m, in \u001b[0;36mCustomHFTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m    598\u001b[0m step \u001b[39m=\u001b[39m \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m\n\u001b[1;32m    599\u001b[0m \u001b[39m# Get a batch\u001b[39;00m\n\u001b[0;32m--> 600\u001b[0m rand_batch \u001b[39m=\u001b[39m \u001b[39mnext\u001b[39;49m(\u001b[39miter\u001b[39;49m(epoch_iterator))\n\u001b[1;32m    601\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m########## epoch iterator\u001b[39m\u001b[39m{\u001b[39;00mrand_batch\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)          \n\u001b[1;32m    602\u001b[0m \u001b[39mfor\u001b[39;00m step, inputs \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(epoch_iterator):\n\u001b[1;32m    603\u001b[0m \n\u001b[1;32m    604\u001b[0m     \u001b[39m# Skip past any already trained steps if resuming training\u001b[39;00m\n",
      "File \u001b[0;32m/mnt/sdc/niallt/venvs/39nlp/lib/python3.9/site-packages/torch/utils/data/dataloader.py:633\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    630\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    631\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    632\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 633\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[1;32m    634\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    635\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    636\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    637\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m/mnt/sdc/niallt/venvs/39nlp/lib/python3.9/site-packages/torch/utils/data/dataloader.py:677\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    675\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_next_data\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    676\u001b[0m     index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_next_index()  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 677\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dataset_fetcher\u001b[39m.\u001b[39;49mfetch(index)  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    678\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory:\n\u001b[1;32m    679\u001b[0m         data \u001b[39m=\u001b[39m _utils\u001b[39m.\u001b[39mpin_memory\u001b[39m.\u001b[39mpin_memory(data, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m/mnt/sdc/niallt/venvs/39nlp/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py:49\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mauto_collation:\n\u001b[1;32m     48\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset, \u001b[39m\"\u001b[39m\u001b[39m__getitems__\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset\u001b[39m.\u001b[39m__getitems__:\n\u001b[0;32m---> 49\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataset\u001b[39m.\u001b[39;49m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n",
      "File \u001b[0;32m/mnt/sdc/niallt/venvs/39nlp/lib/python3.9/site-packages/datasets/arrow_dataset.py:2782\u001b[0m, in \u001b[0;36mDataset.__getitems__\u001b[0;34m(self, keys)\u001b[0m\n\u001b[1;32m   2780\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__getitems__\u001b[39m(\u001b[39mself\u001b[39m, keys: List) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m List:\n\u001b[1;32m   2781\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Can be used to get a batch using a list of integers indices.\"\"\"\u001b[39;00m\n\u001b[0;32m-> 2782\u001b[0m     batch \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m\u001b[39m__getitem__\u001b[39;49m(keys)\n\u001b[1;32m   2783\u001b[0m     n_examples \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(batch[\u001b[39mnext\u001b[39m(\u001b[39miter\u001b[39m(batch))])\n\u001b[1;32m   2784\u001b[0m     \u001b[39mreturn\u001b[39;00m [{col: array[i] \u001b[39mfor\u001b[39;00m col, array \u001b[39min\u001b[39;00m batch\u001b[39m.\u001b[39mitems()} \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(n_examples)]\n",
      "File \u001b[0;32m/mnt/sdc/niallt/venvs/39nlp/lib/python3.9/site-packages/datasets/arrow_dataset.py:2778\u001b[0m, in \u001b[0;36mDataset.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2776\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__getitem__\u001b[39m(\u001b[39mself\u001b[39m, key):  \u001b[39m# noqa: F811\u001b[39;00m\n\u001b[1;32m   2777\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Can be used to index columns (by string names) or rows (by integer index or iterable of indices or bools).\"\"\"\u001b[39;00m\n\u001b[0;32m-> 2778\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_getitem(key)\n",
      "File \u001b[0;32m/mnt/sdc/niallt/venvs/39nlp/lib/python3.9/site-packages/datasets/arrow_dataset.py:2762\u001b[0m, in \u001b[0;36mDataset._getitem\u001b[0;34m(self, key, **kwargs)\u001b[0m\n\u001b[1;32m   2760\u001b[0m format_kwargs \u001b[39m=\u001b[39m format_kwargs \u001b[39mif\u001b[39;00m format_kwargs \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m {}\n\u001b[1;32m   2761\u001b[0m formatter \u001b[39m=\u001b[39m get_formatter(format_type, features\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_info\u001b[39m.\u001b[39mfeatures, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mformat_kwargs)\n\u001b[0;32m-> 2762\u001b[0m pa_subtable \u001b[39m=\u001b[39m query_table(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_data, key, indices\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_indices \u001b[39mif\u001b[39;49;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_indices \u001b[39mis\u001b[39;49;00m \u001b[39mnot\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m \u001b[39melse\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m)\n\u001b[1;32m   2763\u001b[0m formatted_output \u001b[39m=\u001b[39m format_table(\n\u001b[1;32m   2764\u001b[0m     pa_subtable, key, formatter\u001b[39m=\u001b[39mformatter, format_columns\u001b[39m=\u001b[39mformat_columns, output_all_columns\u001b[39m=\u001b[39moutput_all_columns\n\u001b[1;32m   2765\u001b[0m )\n\u001b[1;32m   2766\u001b[0m \u001b[39mreturn\u001b[39;00m formatted_output\n",
      "File \u001b[0;32m/mnt/sdc/niallt/venvs/39nlp/lib/python3.9/site-packages/datasets/formatting/formatting.py:578\u001b[0m, in \u001b[0;36mquery_table\u001b[0;34m(table, key, indices)\u001b[0m\n\u001b[1;32m    576\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    577\u001b[0m     size \u001b[39m=\u001b[39m indices\u001b[39m.\u001b[39mnum_rows \u001b[39mif\u001b[39;00m indices \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m table\u001b[39m.\u001b[39mnum_rows\n\u001b[0;32m--> 578\u001b[0m     _check_valid_index_key(key, size)\n\u001b[1;32m    579\u001b[0m \u001b[39m# Query the main table\u001b[39;00m\n\u001b[1;32m    580\u001b[0m \u001b[39mif\u001b[39;00m indices \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/mnt/sdc/niallt/venvs/39nlp/lib/python3.9/site-packages/datasets/formatting/formatting.py:531\u001b[0m, in \u001b[0;36m_check_valid_index_key\u001b[0;34m(key, size)\u001b[0m\n\u001b[1;32m    529\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(key, Iterable):\n\u001b[1;32m    530\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(key) \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m--> 531\u001b[0m         _check_valid_index_key(\u001b[39mint\u001b[39;49m(\u001b[39mmax\u001b[39;49m(key)), size\u001b[39m=\u001b[39;49msize)\n\u001b[1;32m    532\u001b[0m         _check_valid_index_key(\u001b[39mint\u001b[39m(\u001b[39mmin\u001b[39m(key)), size\u001b[39m=\u001b[39msize)\n\u001b[1;32m    533\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[0;32m/mnt/sdc/niallt/venvs/39nlp/lib/python3.9/site-packages/datasets/formatting/formatting.py:521\u001b[0m, in \u001b[0;36m_check_valid_index_key\u001b[0;34m(key, size)\u001b[0m\n\u001b[1;32m    519\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(key, \u001b[39mint\u001b[39m):\n\u001b[1;32m    520\u001b[0m     \u001b[39mif\u001b[39;00m (key \u001b[39m<\u001b[39m \u001b[39m0\u001b[39m \u001b[39mand\u001b[39;00m key \u001b[39m+\u001b[39m size \u001b[39m<\u001b[39m \u001b[39m0\u001b[39m) \u001b[39mor\u001b[39;00m (key \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m size):\n\u001b[0;32m--> 521\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mIndexError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mInvalid key: \u001b[39m\u001b[39m{\u001b[39;00mkey\u001b[39m}\u001b[39;00m\u001b[39m is out of bounds for size \u001b[39m\u001b[39m{\u001b[39;00msize\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    522\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[1;32m    523\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(key, \u001b[39mslice\u001b[39m):\n",
      "\u001b[0;31mIndexError\u001b[0m: Invalid key: 858 is out of bounds for size 0"
     ]
    }
   ],
   "source": [
    "# set up training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=f\"/mnt/sdd/niallt/saved_models/code_testing/note_mlm/\",\n",
    "    max_steps= 10,\n",
    "    num_train_epochs=5,\n",
    "    \n",
    "    # per_device_train_batch_size=args.train_batch_size, # seems auto handeled by HF trainer now\n",
    "    # per_device_eval_batch_size = args.eval_batch_size,\n",
    "\n",
    "    learning_rate = 2e-5,\n",
    "    weight_decay = 0.01,\n",
    "    \n",
    "    evaluation_strategy = \"steps\",\n",
    "    eval_steps = 10,\n",
    "    save_strategy=\"no\",        \n",
    "    save_steps=200,\n",
    "    save_total_limit=2,\n",
    "    load_best_model_at_end = False,\n",
    "    \n",
    "    warmup_steps=5,\n",
    "    gradient_accumulation_steps=1,\n",
    "    logging_steps=5,\n",
    "    logging_first_step=True,\n",
    "    logging_strategy = 'steps',\n",
    "    logging_dir = f\"/mnt/sdd/niallt/saved_models/code_testing/note_mlm/\",\n",
    "    remove_unused_columns=True\n",
    ")\n",
    "\n",
    "# set up the trainer\n",
    "trainer = CustomHFTrainer(\n",
    "    model=model,\n",
    "    tokenizer = tokenizer,\n",
    "    args=training_args,\n",
    "    data_collator=data_collator,\n",
    "    train_dataset=lm_datasets[\"train\"],\n",
    "    eval_dataset = lm_datasets['valid'],\n",
    "   \n",
    "    # compute_metrics = compute_metrics,\n",
    "    # preprocess_logits_for_metrics = preprocess_logits_for_metrics\n",
    ")\n",
    "# run trainer\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'TransformerForPreTraining' object has no attribute 'return_dict'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "File \u001b[0;32m/mnt/sdc/niallt/venvs/39nlp/lib/python3.9/site-packages/peft/peft_model.py:408\u001b[0m, in \u001b[0;36mPeftModel.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    407\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 408\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__getattr__\u001b[39;49m(name)  \u001b[39m# defer to nn.Module's logic\u001b[39;00m\n\u001b[1;32m    409\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mAttributeError\u001b[39;00m:\n",
      "File \u001b[0;32m/mnt/sdc/niallt/venvs/39nlp/lib/python3.9/site-packages/torch/nn/modules/module.py:1614\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1613\u001b[0m         \u001b[39mreturn\u001b[39;00m modules[name]\n\u001b[0;32m-> 1614\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mAttributeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m object has no attribute \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[1;32m   1615\u001b[0m     \u001b[39mtype\u001b[39m(\u001b[39mself\u001b[39m)\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m, name))\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'PeftModel' object has no attribute 'return_dict'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "File \u001b[0;32m/mnt/sdc/niallt/venvs/39nlp/lib/python3.9/site-packages/peft/tuners/lora.py:382\u001b[0m, in \u001b[0;36mLoraModel.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    381\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 382\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__getattr__\u001b[39;49m(name)  \u001b[39m# defer to nn.Module's logic\u001b[39;00m\n\u001b[1;32m    383\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mAttributeError\u001b[39;00m:\n",
      "File \u001b[0;32m/mnt/sdc/niallt/venvs/39nlp/lib/python3.9/site-packages/torch/nn/modules/module.py:1614\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1613\u001b[0m         \u001b[39mreturn\u001b[39;00m modules[name]\n\u001b[0;32m-> 1614\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mAttributeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m object has no attribute \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[1;32m   1615\u001b[0m     \u001b[39mtype\u001b[39m(\u001b[39mself\u001b[39m)\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m, name))\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'LoraModel' object has no attribute 'return_dict'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model\u001b[39m.\u001b[39;49mreturn_dict\n",
      "File \u001b[0;32m/mnt/sdc/niallt/venvs/39nlp/lib/python3.9/site-packages/peft/peft_model.py:410\u001b[0m, in \u001b[0;36mPeftModel.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    408\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m\u001b[39m__getattr__\u001b[39m(name)  \u001b[39m# defer to nn.Module's logic\u001b[39;00m\n\u001b[1;32m    409\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mAttributeError\u001b[39;00m:\n\u001b[0;32m--> 410\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mgetattr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbase_model, name)\n",
      "File \u001b[0;32m/mnt/sdc/niallt/venvs/39nlp/lib/python3.9/site-packages/peft/tuners/lora.py:384\u001b[0m, in \u001b[0;36mLoraModel.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    382\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m\u001b[39m__getattr__\u001b[39m(name)  \u001b[39m# defer to nn.Module's logic\u001b[39;00m\n\u001b[1;32m    383\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mAttributeError\u001b[39;00m:\n\u001b[0;32m--> 384\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mgetattr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel, name)\n",
      "File \u001b[0;32m/mnt/sdc/niallt/venvs/39nlp/lib/python3.9/site-packages/torch/nn/modules/module.py:1614\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1612\u001b[0m     \u001b[39mif\u001b[39;00m name \u001b[39min\u001b[39;00m modules:\n\u001b[1;32m   1613\u001b[0m         \u001b[39mreturn\u001b[39;00m modules[name]\n\u001b[0;32m-> 1614\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mAttributeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m object has no attribute \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[1;32m   1615\u001b[0m     \u001b[39mtype\u001b[39m(\u001b[39mself\u001b[39m)\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m, name))\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'TransformerForPreTraining' object has no attribute 'return_dict'"
     ]
    }
   ],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test contrastive loss functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_metric_learning import losses\n",
    "# loss_func = losses.TripletMarginLoss()\n",
    "# loss_func = losses.SupConLoss(temperature=0.1)\n",
    "loss_func = losses.NTXentLoss(temperature=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(\n",
    "    lm_datasets['train'],  collate_fn = data_collator,batch_size=8, shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labels are: tensor([1, 0, 3, 0, 0, 0, 0, 8])\n"
     ]
    }
   ],
   "source": [
    "for batch in train_loader:\n",
    "    model.eval()\n",
    "    outputs = model(**batch)\n",
    "    seq_embeddings = outputs.seq_embedding\n",
    "    print(f\"labels are: {batch['category_label']}\")\n",
    "    loss = loss_func(seq_embeddings, batch['category_label'])\n",
    "    break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.2314, grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [1,2,2,2,1,3,4,5,6,7,7,8,8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = np.unique(labels)\n",
    "label_to_idx = {x: i for i, x in enumerate(num_classes)}\n",
    "positive_idxs = [np.where(labels == i)[0] for i in num_classes]\n",
    "negative_idxs = [np.where(labels != i)[0] for i in num_classes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: 0, 2: 1, 3: 2, 4: 3, 5: 4, 6: 5, 7: 6, 8: 7}"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_to_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([0, 4]),\n",
       " array([1, 2, 3]),\n",
       " array([5]),\n",
       " array([6]),\n",
       " array([7]),\n",
       " array([8]),\n",
       " array([ 9, 10]),\n",
       " array([11, 12])]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positive_idxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([ 1,  2,  3,  5,  6,  7,  8,  9, 10, 11, 12]),\n",
       " array([ 0,  4,  5,  6,  7,  8,  9, 10, 11, 12]),\n",
       " array([ 0,  1,  2,  3,  4,  6,  7,  8,  9, 10, 11, 12]),\n",
       " array([ 0,  1,  2,  3,  4,  5,  7,  8,  9, 10, 11, 12]),\n",
       " array([ 0,  1,  2,  3,  4,  5,  6,  8,  9, 10, 11, 12]),\n",
       " array([ 0,  1,  2,  3,  4,  5,  6,  7,  9, 10, 11, 12]),\n",
       " array([ 0,  1,  2,  3,  4,  5,  6,  7,  8, 11, 12]),\n",
       " array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10])]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "negative_idxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoder_model = \"/mnt/sdc/niallt/saved_models/language_modelling/mimic/mimic-roberta-base/sampled_250000/22-12-2022--12-45/checkpoint-100000\"\n",
    "encoder_model = \"/mnt/sdc/niallt/saved_models/declutr/mimic/few_epoch/mimic-roberta-base/2_anch_2_pos_min_1024/transformer_format/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    " \n",
    "if \"saved_models\" in encoder_model:\n",
    "    if \"declutr\" in encoder_model:\n",
    "        if \"few_epoch\" in encoder_model:\n",
    "            if \"span_comparison\" in encoder_model:\n",
    "                model_name = encoder_model.split(\"/\")[9] + \"/declutr/\" + encoder_model.split(\"/\")[-3]\n",
    "            else:\n",
    "                model_name = encoder_model.split(\"/\")[8] + \"/declutr/\" + encoder_model.split(\"/\")[-3]\n",
    "\n",
    "        else:\n",
    "            model_name = encoder_model.split(\"/\")[7] + \"/declutr/\" + encoder_model.split(\"/\")[-3]\n",
    "    elif \"contrastive\" in encoder_model or \"custom_pretraining\" in encoder_model:\n",
    "        print(\"contrastive or custom_pretraining\")\n",
    "        model_name = encoder_model.split(\"/\")[7]\n",
    "    else:\n",
    "        print(\"mlm only\")\n",
    "        model_name = encoder_model.split(\"/\")[7] + \"/mlm_only/\"\n",
    "else:    \n",
    "    model_name = encoder_model.split(\"/\")[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['',\n",
       " 'mnt',\n",
       " 'sdc',\n",
       " 'niallt',\n",
       " 'saved_models',\n",
       " 'declutr',\n",
       " 'mimic',\n",
       " 'few_epoch',\n",
       " 'mimic-roberta-base',\n",
       " '2_anch_2_pos_min_1024',\n",
       " 'transformer_format']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_model.split(\"/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'mimic-roberta-base/declutr/2_anch_2_pos_min_1024'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test PEFT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file config.json from cache at /home/niallt/.cache/huggingface/hub/models--roberta-base/snapshots/bc2764f8af2e92b6eb5679868df33e224075ca68/config.json\n",
      "Model config RobertaConfig {\n",
      "  \"_name_or_path\": \"roberta-base\",\n",
      "  \"architectures\": [\n",
      "    \"RobertaForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.30.2\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "loading weights file model.safetensors from cache at /home/niallt/.cache/huggingface/hub/models--roberta-base/snapshots/bc2764f8af2e92b6eb5679868df33e224075ca68/model.safetensors\n",
      "All model checkpoint weights were used when initializing RobertaForMaskedLM.\n",
      "\n",
      "All the weights of RobertaForMaskedLM were initialized from the model checkpoint at roberta-base.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use RobertaForMaskedLM for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "# reload trained model\n",
    "\n",
    "# peft_model_dir = \"/mnt/sdc/niallt/saved_models/language_modelling/mimic/roberta-base-mimic-note-custom_pretraining_max_epoch_1_lora/sampled_250000/19-07-2023--16-49/checkpoint-14000/\"\n",
    "peft_model_dir = \"/mnt/sdc/niallt/saved_models/language_modelling/mimic/roberta-base-mimic-wecho-LORA/sampled_250000/28-08-2023--12-46/checkpoint-78000\"\n",
    "encoder_model = \"roberta-base\"\n",
    "# load config\n",
    "config = PeftConfig.from_pretrained(peft_model_dir)\n",
    "# load base model \n",
    "original_model = AutoModelForMaskedLM.from_pretrained(encoder_model)\n",
    "# original_model = TransformerForPreTraining.from_pretrained(config.base_model_name_or_path)\n",
    "# load peft model\n",
    "reloaded_peft_model = PeftModel.from_pretrained(original_model, peft_model_dir)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PeftConfig(peft_type='LORA', auto_mapping={'base_model_class': 'RobertaForMaskedLM', 'parent_library': 'transformers.models.roberta.modeling_roberta'}, base_model_name_or_path='roberta-base', revision=None, task_type=None, inference_mode=True)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PeftModel(\n",
       "  (base_model): LoraModel(\n",
       "    (model): RobertaForMaskedLM(\n",
       "      (roberta): RobertaModel(\n",
       "        (embeddings): RobertaEmbeddings(\n",
       "          (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
       "          (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "          (token_type_embeddings): Embedding(1, 768)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (encoder): RobertaEncoder(\n",
       "          (layer): ModuleList(\n",
       "            (0-11): 12 x RobertaLayer(\n",
       "              (attention): RobertaAttention(\n",
       "                (self): RobertaSelfAttention(\n",
       "                  (query): Linear(\n",
       "                    in_features=768, out_features=768, bias=True\n",
       "                    (lora_dropout): ModuleDict(\n",
       "                      (default): Dropout(p=0.1, inplace=False)\n",
       "                    )\n",
       "                    (lora_A): ModuleDict(\n",
       "                      (default): Linear(in_features=768, out_features=64, bias=False)\n",
       "                    )\n",
       "                    (lora_B): ModuleDict(\n",
       "                      (default): Linear(in_features=64, out_features=768, bias=False)\n",
       "                    )\n",
       "                    (lora_embedding_A): ParameterDict()\n",
       "                    (lora_embedding_B): ParameterDict()\n",
       "                  )\n",
       "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (value): Linear(\n",
       "                    in_features=768, out_features=768, bias=True\n",
       "                    (lora_dropout): ModuleDict(\n",
       "                      (default): Dropout(p=0.1, inplace=False)\n",
       "                    )\n",
       "                    (lora_A): ModuleDict(\n",
       "                      (default): Linear(in_features=768, out_features=64, bias=False)\n",
       "                    )\n",
       "                    (lora_B): ModuleDict(\n",
       "                      (default): Linear(in_features=64, out_features=768, bias=False)\n",
       "                    )\n",
       "                    (lora_embedding_A): ParameterDict()\n",
       "                    (lora_embedding_B): ParameterDict()\n",
       "                  )\n",
       "                  (dropout): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (output): RobertaSelfOutput(\n",
       "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                  (dropout): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (intermediate): RobertaIntermediate(\n",
       "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "                (intermediate_act_fn): GELUActivation()\n",
       "              )\n",
       "              (output): RobertaOutput(\n",
       "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (lm_head): RobertaLMHead(\n",
       "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (decoder): Linear(in_features=768, out_features=50265, bias=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reloaded_peft_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\"> </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> </span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;module&gt;</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span>                                                                                    <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span> <span style=\"color: #800000; text-decoration-color: #800000\"> </span>1 count_parameters(reloaded_peft_model)                                                        <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2 </span>                                                                                             <span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\"></span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">NameError: </span>name <span style=\"color: #008000; text-decoration-color: #008000\">'count_parameters'</span> is not defined\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[31m\u001b[0m\u001b[31m\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m\u001b[0m\u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m in \u001b[92m<module>\u001b[0m:\u001b[94m1\u001b[0m                                                                                    \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m                                                                                                  \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m \u001b[31m \u001b[0m1 count_parameters(reloaded_peft_model)                                                        \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m   \u001b[2m2 \u001b[0m                                                                                             \u001b[31m\u001b[0m\n",
       "\u001b[31m\u001b[0m\n",
       "\u001b[1;91mNameError: \u001b[0mname \u001b[32m'count_parameters'\u001b[0m is not defined\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "count_parameters(reloaded_peft_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file config.json from cache at /home/niallt/.cache/huggingface/hub/models--roberta-base/snapshots/bc2764f8af2e92b6eb5679868df33e224075ca68/config.json\n",
      "Model config MeanRobertaConfig {\n",
      "  \"architectures\": [\n",
      "    \"RobertaForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"compute_contrastive\": null,\n",
      "  \"contrastive_loss_weight\": 1.0,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_pretraining_labels\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.30.2\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "loading weights file model.safetensors from cache at /home/niallt/.cache/huggingface/hub/models--roberta-base/snapshots/bc2764f8af2e92b6eb5679868df33e224075ca68/model.safetensors\n",
      "All model checkpoint weights were used when initializing TransformerForPreTraining.\n",
      "\n",
      "Some weights of TransformerForPreTraining were not initialized from the model checkpoint at roberta-base and are newly initialized: ['lm_head.decoder.bias', 'lm_head.decoder.weight', 'seq_classifier.classifier.weight', 'seq_classifier.classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# using pretrained class\n",
    "\n",
    "reloaded_pretrained_model = PeftModel.from_pretrained(TransformerForPreTraining.from_pretrained(\"roberta-base\"), peft_model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-0.0366, -0.0454,  0.0340,  ...,  0.0209, -0.0275,  0.0043],\n",
       "        [-0.0124, -0.0309, -0.0112,  ...,  0.0028, -0.0017,  0.0118],\n",
       "        [-0.0257,  0.0028,  0.0073,  ..., -0.0129, -0.0434,  0.0093],\n",
       "        ...,\n",
       "        [ 0.0148,  0.0063,  0.0246,  ...,  0.0279, -0.0199, -0.0034],\n",
       "        [-0.0222,  0.0434,  0.0112,  ..., -0.0060, -0.0374, -0.0553],\n",
       "        [-0.0138, -0.0138, -0.0105,  ...,  0.0176,  0.0340,  0.0087]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# view lora weights of model\n",
    "\n",
    "\n",
    "reloaded_pretrained_model.base_model.model.roberta.encoder.layer[0].attention.self.query.lora_A.default.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge weights?\n",
    "\n",
    "merged_model = reloaded_peft_model.merge_and_unload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TransformerForPreTraining(\n",
       "  (roberta): RobertaModel(\n",
       "    (embeddings): RobertaEmbeddings(\n",
       "      (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
       "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "      (token_type_embeddings): Embedding(1, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): RobertaEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (lm_head): RobertaLMHead(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "    (decoder): Linear(in_features=768, out_features=50265, bias=True)\n",
       "  )\n",
       "  (seq_classifier): MeanSequenceClassifier(\n",
       "    (classifier): Linear(in_features=768, out_features=12, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### save merged model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_model.save_pretrained()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 0 || all params: 124,706,661 || trainable%: 0.0\n"
     ]
    }
   ],
   "source": [
    "reloaded_peft_model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file config.json from cache at /home/niallt/.cache/huggingface/hub/models--roberta-base/snapshots/bc2764f8af2e92b6eb5679868df33e224075ca68/config.json\n",
      "Model config RobertaConfig {\n",
      "  \"_name_or_path\": \"roberta-base\",\n",
      "  \"architectures\": [\n",
      "    \"RobertaForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.30.2\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "loading weights file model.safetensors from cache at /home/niallt/.cache/huggingface/hub/models--roberta-base/snapshots/bc2764f8af2e92b6eb5679868df33e224075ca68/model.safetensors\n",
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForSequenceClassification: ['lm_head.dense.weight', 'lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.bias']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.out_proj.weight', 'classifier.out_proj.bias', 'classifier.dense.bias', 'classifier.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# can we also reload this model into the automodel classes directly?\n",
    "\n",
    "\n",
    "# load base model \n",
    "original_auto_model = AutoModelForSequenceClassification.from_pretrained(config.base_model_name_or_path)\n",
    "# load peft model\n",
    "reloaded_auto_peft_model = PeftModel.from_pretrained(original_auto_model, peft_model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PeftModel(\n",
       "  (base_model): LoraModel(\n",
       "    (model): RobertaForSequenceClassification(\n",
       "      (roberta): RobertaModel(\n",
       "        (embeddings): RobertaEmbeddings(\n",
       "          (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
       "          (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "          (token_type_embeddings): Embedding(1, 768)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (encoder): RobertaEncoder(\n",
       "          (layer): ModuleList(\n",
       "            (0-11): 12 x RobertaLayer(\n",
       "              (attention): RobertaAttention(\n",
       "                (self): RobertaSelfAttention(\n",
       "                  (query): Linear(\n",
       "                    in_features=768, out_features=768, bias=True\n",
       "                    (lora_dropout): ModuleDict(\n",
       "                      (default): Dropout(p=0.1, inplace=False)\n",
       "                    )\n",
       "                    (lora_A): ModuleDict(\n",
       "                      (default): Linear(in_features=768, out_features=8, bias=False)\n",
       "                    )\n",
       "                    (lora_B): ModuleDict(\n",
       "                      (default): Linear(in_features=8, out_features=768, bias=False)\n",
       "                    )\n",
       "                    (lora_embedding_A): ParameterDict()\n",
       "                    (lora_embedding_B): ParameterDict()\n",
       "                  )\n",
       "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (value): Linear(\n",
       "                    in_features=768, out_features=768, bias=True\n",
       "                    (lora_dropout): ModuleDict(\n",
       "                      (default): Dropout(p=0.1, inplace=False)\n",
       "                    )\n",
       "                    (lora_A): ModuleDict(\n",
       "                      (default): Linear(in_features=768, out_features=8, bias=False)\n",
       "                    )\n",
       "                    (lora_B): ModuleDict(\n",
       "                      (default): Linear(in_features=8, out_features=768, bias=False)\n",
       "                    )\n",
       "                    (lora_embedding_A): ParameterDict()\n",
       "                    (lora_embedding_B): ParameterDict()\n",
       "                  )\n",
       "                  (dropout): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (output): RobertaSelfOutput(\n",
       "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                  (dropout): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (intermediate): RobertaIntermediate(\n",
       "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "                (intermediate_act_fn): GELUActivation()\n",
       "              )\n",
       "              (output): RobertaOutput(\n",
       "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (classifier): RobertaClassificationHead(\n",
       "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=2, bias=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reloaded_auto_peft_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-0.0366, -0.0454,  0.0340,  ...,  0.0209, -0.0275,  0.0043],\n",
       "        [-0.0124, -0.0309, -0.0112,  ...,  0.0028, -0.0017,  0.0118],\n",
       "        [-0.0257,  0.0028,  0.0073,  ..., -0.0129, -0.0434,  0.0093],\n",
       "        ...,\n",
       "        [ 0.0148,  0.0063,  0.0246,  ...,  0.0279, -0.0199, -0.0034],\n",
       "        [-0.0222,  0.0434,  0.0112,  ..., -0.0060, -0.0374, -0.0553],\n",
       "        [-0.0138, -0.0138, -0.0105,  ...,  0.0176,  0.0340,  0.0087]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reloaded_auto_peft_model.base_model.model.roberta.encoder.layer[0].attention.self.query.lora_A.default.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_auto_model = reloaded_auto_peft_model.merge_and_unload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RobertaForSequenceClassification(\n",
       "  (roberta): RobertaModel(\n",
       "    (embeddings): RobertaEmbeddings(\n",
       "      (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
       "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "      (token_type_embeddings): Embedding(1, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): RobertaEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (classifier): RobertaClassificationHead(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (out_proj): Linear(in_features=768, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_auto_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_parameters(merged_auto_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file config.json from cache at /home/niallt/.cache/huggingface/hub/models--roberta-base/snapshots/bc2764f8af2e92b6eb5679868df33e224075ca68/config.json\n",
      "Model config RobertaConfig {\n",
      "  \"_name_or_path\": \"roberta-base\",\n",
      "  \"architectures\": [\n",
      "    \"RobertaForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.30.2\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "loading weights file model.safetensors from cache at /home/niallt/.cache/huggingface/hub/models--roberta-base/snapshots/bc2764f8af2e92b6eb5679868df33e224075ca68/model.safetensors\n",
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForSequenceClassification: ['lm_head.dense.weight', 'lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.bias']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.out_proj.weight', 'classifier.out_proj.bias', 'classifier.dense.bias', 'classifier.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "auto_model = AutoModelForSequenceClassification.from_pretrained(\"roberta-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RobertaForSequenceClassification(\n",
       "  (roberta): RobertaModel(\n",
       "    (embeddings): RobertaEmbeddings(\n",
       "      (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
       "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "      (token_type_embeddings): Embedding(1, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): RobertaEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (classifier): RobertaClassificationHead(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (out_proj): Linear(in_features=768, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auto_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "124647170"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_parameters(auto_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dfsad\n"
     ]
    }
   ],
   "source": [
    "name = \"roberta-base-lora\"\n",
    "if \"LORA\" in name or \"lora\" in name:\n",
    "    print(f\"dfsad\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "unfreeze_model(merged_auto_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "124647170"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_parameters(merged_auto_model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "39nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4bf09d40e77d3786deb49768c5a0e6c92c433b20cf5c332bc185780ac9d11fb5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
